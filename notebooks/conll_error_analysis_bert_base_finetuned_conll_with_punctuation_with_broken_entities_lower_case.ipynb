{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.8.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 10000)\n",
    "pd.set_option('display.max_columns', 10000)\n",
    "pd.set_option('display.width', 10000)\n",
    "pd.set_option('max_colwidth', 10000)\n",
    "import numpy as np\n",
    "from tqdm import tqdm, trange\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertTokenizer, BertConfig\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import transformers\n",
    "from transformers import BertForTokenClassification, AdamW\n",
    "from seqeval.metrics import f1_score, accuracy_score\n",
    "import Levenshtein\n",
    "import string\n",
    "import difflib\n",
    "\n",
    "transformers.__version__\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_values = ['O', 'PER', 'LOC', 'ORG']\n",
    "#tag_values = ['B-ORG', 'O', 'B-MISC', 'B-PER', 'I-PER', 'B-LOC', 'I-ORG', 'I-MISC', 'I-LOC']\n",
    "tag_values.append(\"PAD\")\n",
    "tag2idx = {t: i for i, t in enumerate(tag_values)}\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_whole_word_mask=True)\n",
    "model = BertForTokenClassification.from_pretrained(\"bert-base-uncased\", num_labels=len(tag2idx), output_attentions = False, output_hidden_states = False)\n",
    "model.load_state_dict(torch.load(\"../model_2/bert_base_conll_with_punctuation_with_broken_entities_broken_context_75.pt\", map_location=torch.device('cpu')), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_for_test(filepath):\n",
    "    df = pd.read_csv(filepath)\n",
    "    df.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "    print(df.isnull().sum())\n",
    "    g_test = df.groupby(\"Sentence #\")\n",
    "    test_df = pd.DataFrame({\"Sentence\": g_test.apply(lambda sdf: \" \".join(sdf.Word)),\n",
    "                       \"Tag\": g_test.apply(lambda sdf: \",\".join(sdf.Tag))})\n",
    "    test_df.reset_index(inplace=True)\n",
    "    return df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_test(data, tokenizer, model):\n",
    "    test = []\n",
    "    #results = open(\"conll03_base_ljspeech_asr_test_without_gpe_uncased_results_lower.txt\", \"a+\")\n",
    "    #test_data=original_data['sentence'].values.tolist()\n",
    "    #test_data=original_sentence\n",
    "    #test_data=test_df['Sentence'].values.tolist()\n",
    "    test_data=data\n",
    "\n",
    "    # ASR TEST DATE LATEST\n",
    "    sentence_no = 0\n",
    "    for data in test_data:\n",
    "        tokenized_sentence = tokenizer.encode(data.lower().strip())\n",
    "        if len(tokenized_sentence) >= 511:\n",
    "            print(str(sentence_no) + \"---\" + str(len(tokenized_sentence)))\n",
    "            print(tokenized_sentence)\n",
    "            continue\n",
    "        #tokenized_sentence = nlp(data.lower().strip())\n",
    "        input_ids = torch.tensor([tokenized_sentence])\n",
    "        #input_ids = torch.tensor([tokenized_sentence._.trf_word_pieces])\n",
    "\n",
    "        with torch.no_grad():\n",
    "             output = model(input_ids)\n",
    "        label_indices = np.argmax(output[0].to('cpu').numpy(), axis=2)\n",
    "\n",
    "        # join bpe split tokens\n",
    "        tokens = tokenizer.convert_ids_to_tokens(input_ids.to('cpu').numpy()[0])\n",
    "        #tokens = _.trf_word_pieces_\n",
    "        new_tokens, new_labels = [], []\n",
    "        for token, label_idx in zip(tokens, label_indices[0]):\n",
    "            if token.startswith(\"##\"):\n",
    "                new_tokens[-1] = new_tokens[-1] + token[2:]\n",
    "            else:\n",
    "                new_labels.append(tag_values[label_idx])\n",
    "                new_tokens.append(token)\n",
    "\n",
    "        for token, label in zip(new_tokens, new_labels):\n",
    "            #result = str(sentence_no) + \"\\t\" + label + \"\\t\" + token + \"\\n\"\n",
    "            #results.write(result)\n",
    "            test.append((str(sentence_no), label, token))\n",
    "        sentence_no = sentence_no + 1\n",
    "    test_df = pd.DataFrame(test, columns=['sentence_no', 'labels', 'token'])\n",
    "    return test_df\n",
    "    #test_df.to_csv(\"final_asr_test_dataframe.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_model_output(test_df, df):\n",
    "    indexNames = test_df[test_df['token'] == \"[CLS]\" ].index\n",
    "    test_df.drop(indexNames, inplace=True)\n",
    "    indexNames = test_df[test_df['token'] == \"[SEP]\" ].index\n",
    "    test_df.drop(indexNames, inplace=True)\n",
    "    test_df.reset_index(drop=True, inplace=True)\n",
    "    test_df['label_asr'] = df['Tag']\n",
    "    test_df['token_asr'] = df['Word']\n",
    "    return test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistics(test_df, tags):\n",
    "    new_acc = accuracy_score(test_df['labels'].values.tolist(), test_df['label_asr'].values.tolist())\n",
    "    print(new_acc)\n",
    "\n",
    "    new_f1 = f1_score(test_df['labels'].values.tolist(), test_df['label_asr'].values.tolist())\n",
    "    print(new_f1)\n",
    "    print(\"---STATISTICS ON EACH LABEL---\")\n",
    "    for tag in tags:\n",
    "        true_positive = test_df[((test_df['labels'].str.contains(tag)) & (test_df['label_asr'].str.contains(tag)))]\n",
    "        print(len(true_positive))\n",
    "        false_positive = test_df[((test_df['labels'].str.contains(tag)) & (~test_df['label_asr'].str.contains(tag)))]\n",
    "        print(len(false_positive))\n",
    "        false_negative = test_df[((~test_df['labels'].str.contains(tag)) & (test_df['label_asr'].str.contains(tag)))]\n",
    "        print(len(false_negative))\n",
    "        true_negative = test_df[((~test_df['labels'].str.contains(tag)) & (~test_df['label_asr'].str.contains(tag)))]\n",
    "        print(len(true_negative))\n",
    "        prec = len(true_positive) / (len(true_positive) + len(false_positive))\n",
    "        print(prec)\n",
    "        recall = len(true_positive) / (len(true_positive) + len(false_negative))\n",
    "        print(recall)\n",
    "        f_measure = (2 * prec * recall) / (prec + recall)\n",
    "        print(f_measure)\n",
    "        print(\"---------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence #    0\n",
      "Word          0\n",
      "Tag           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df, test_df = prepare_data_for_test('../data/conll_test_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>SOCCER</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>JAPAN</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>GET</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>LUCKY</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentence #    Word  Tag\n",
       "0           0  SOCCER    O\n",
       "1           0       -    O\n",
       "2           0   JAPAN  LOC\n",
       "3           0     GET    O\n",
       "4           0   LUCKY    O"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1621</th>\n",
       "      <td>1621</td>\n",
       "      <td>That is why this is so emotional a night for me , Charlton said .</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,PER,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1622</th>\n",
       "      <td>1622</td>\n",
       "      <td>It was the joy that we all had over the period , that I shared with people that I grew to love , that I treasure most , he added .</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1623</th>\n",
       "      <td>1623</td>\n",
       "      <td>Charlton managed Ireland for 93 matches , during which time they lost only 17 times in almost 10 years until he resigned in December 1995 .</td>\n",
       "      <td>PER,O,LOC,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1624</th>\n",
       "      <td>1624</td>\n",
       "      <td>He guided Ireland to two successive World Cup finals tournaments and to the 1988 European championship finals in Germany , after the Irish beat a well - fancied England team 1 - 0 in their group qualifier .</td>\n",
       "      <td>O,O,LOC,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,LOC,O,O,O,O,O,O,O,O,O,LOC,O,O,O,O,O,O,O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1625</th>\n",
       "      <td>1625</td>\n",
       "      <td>The lanky former Leeds United defender did not make his England debut until the age of 30 but eventually won 35 caps and was a key member of the 1966 World Cup winning team with his younger brother , Bobby .</td>\n",
       "      <td>O,O,O,ORG,ORG,O,O,O,O,O,LOC,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,PER,O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sentence #                                                                                                                                                                                                         Sentence                                                                                        Tag\n",
       "1621        1621                                                                                                                                                That is why this is so emotional a night for me , Charlton said .                                                            O,O,O,O,O,O,O,O,O,O,O,O,PER,O,O\n",
       "1622        1622                                                                               It was the joy that we all had over the period , that I shared with people that I grew to love , that I treasure most , he added .                              O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O\n",
       "1623        1623                                                                      Charlton managed Ireland for 93 matches , during which time they lost only 17 times in almost 10 years until he resigned in December 1995 .                                    PER,O,LOC,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O\n",
       "1624        1624   He guided Ireland to two successive World Cup finals tournaments and to the 1988 European championship finals in Germany , after the Irish beat a well - fancied England team 1 - 0 in their group qualifier .          O,O,LOC,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,LOC,O,O,O,O,O,O,O,O,O,LOC,O,O,O,O,O,O,O,O,O\n",
       "1625        1625  The lanky former Leeds United defender did not make his England debut until the age of 30 but eventually won 35 caps and was a key member of the 1966 World Cup winning team with his younger brother , Bobby .  O,O,O,ORG,ORG,O,O,O,O,O,LOC,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,PER,O"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>899</td>\n",
       "      <td>- Canadian Grain Commission Visible Supplies Farmers Deliveries Curr Wk Yr Ago Curr Wk Yr to Date Yr Ago Wheat 4320 . 2 3909 . 3 288 . 5 6278 . 9 5580 . 0 Durum 1168 . 9 1225 . 0 44 . 3 965 . 3 1069 . 6 Oats 286 . 5 284 . 6 31 . 9 937 . 3 581 . 2 Barley 1074 . 0 1104 . 8 178 . 0 2531 . 4 1897 . 1 Rye 44 . 6 86 . 3 2 . 3 108 . 2 119 . 2 Flax 165 . 2 181 . 9 14 . 9 231 . 4 332 . 9 Canola 646 . 6 769 . 4 60 . 5 1902 . 0 2147 . 6 Corn 79 . 6 163 . 5 9 . 4 95 . 7 252 . 0 Total 7785 . 8 7724 . 8 629 . 8 13050 . 2 11979 . 6 Exports Domestic Disappearance Curr Wk YTD Yr Ago Curr Wk YTD Yr Ago Wheat 387 . 4 4677 . 8 4553 . 6 55 . 2 1039 . 7 846 . 1 Durum 129 . 0 1515 . 9 1220 . 6 4 . 6 75 . 8 73 . 3 Oats 40 . 0 561 . 0 391 . 9 4 . 8 149 . 6 115 . 0 Barley 110 . 8 1203 . 4 506 . 0 48 . 2 941 . 0 786 . 6 Rye 4 . 1 60 . 7 57 . 9 3 . 0 10 . 7 18 . 9 Flax 7 . 2 154 . 1 235 . 7 1 . 1 22 . 2 15 . 7 Canola 47 . 1 988 . 1 1135 . 5 46 . 7 894 . 9 822 . 0 Corn 4 . 4 15 . 1 87 . 0 0 . 6 22 . 1 11 . 1 Total 730 . 0 9176 . 1 8188 . 2 164 . 2 3156 . 0 2686 . 7 In addition , Statistics Canada indicated the following exports to the U . S . between August and September 1996 , in tonnes : Oats Rye Flaxseed Canola Corn Exports 29 , 200 17 , 200 7 , 700 100 59 , 400 Year Ago 47 , 000 24 , 300 8 , 700 8 , 200 12 , 200 ( Chicago newsdesk 312 408 8720 ) - DOCSTART - NYMEX natgas ends sharply lower on weather outlook .</td>\n",
       "      <td>O,ORG,ORG,ORG,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,ORG,ORG,O,O,O,O,O,O,LOC,LOC,LOC,LOC,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,LOC,O,O,O,O,O,O,O,O,ORG,O,O,O,O,O,O,O,O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sentence #                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Sentence                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Tag\n",
       "899         899  - Canadian Grain Commission Visible Supplies Farmers Deliveries Curr Wk Yr Ago Curr Wk Yr to Date Yr Ago Wheat 4320 . 2 3909 . 3 288 . 5 6278 . 9 5580 . 0 Durum 1168 . 9 1225 . 0 44 . 3 965 . 3 1069 . 6 Oats 286 . 5 284 . 6 31 . 9 937 . 3 581 . 2 Barley 1074 . 0 1104 . 8 178 . 0 2531 . 4 1897 . 1 Rye 44 . 6 86 . 3 2 . 3 108 . 2 119 . 2 Flax 165 . 2 181 . 9 14 . 9 231 . 4 332 . 9 Canola 646 . 6 769 . 4 60 . 5 1902 . 0 2147 . 6 Corn 79 . 6 163 . 5 9 . 4 95 . 7 252 . 0 Total 7785 . 8 7724 . 8 629 . 8 13050 . 2 11979 . 6 Exports Domestic Disappearance Curr Wk YTD Yr Ago Curr Wk YTD Yr Ago Wheat 387 . 4 4677 . 8 4553 . 6 55 . 2 1039 . 7 846 . 1 Durum 129 . 0 1515 . 9 1220 . 6 4 . 6 75 . 8 73 . 3 Oats 40 . 0 561 . 0 391 . 9 4 . 8 149 . 6 115 . 0 Barley 110 . 8 1203 . 4 506 . 0 48 . 2 941 . 0 786 . 6 Rye 4 . 1 60 . 7 57 . 9 3 . 0 10 . 7 18 . 9 Flax 7 . 2 154 . 1 235 . 7 1 . 1 22 . 2 15 . 7 Canola 47 . 1 988 . 1 1135 . 5 46 . 7 894 . 9 822 . 0 Corn 4 . 4 15 . 1 87 . 0 0 . 6 22 . 1 11 . 1 Total 730 . 0 9176 . 1 8188 . 2 164 . 2 3156 . 0 2686 . 7 In addition , Statistics Canada indicated the following exports to the U . S . between August and September 1996 , in tonnes : Oats Rye Flaxseed Canola Corn Exports 29 , 200 17 , 200 7 , 700 100 59 , 400 Year Ago 47 , 000 24 , 300 8 , 700 8 , 200 12 , 200 ( Chicago newsdesk 312 408 8720 ) - DOCSTART - NYMEX natgas ends sharply lower on weather outlook .  O,ORG,ORG,ORG,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,ORG,ORG,O,O,O,O,O,O,LOC,LOC,LOC,LOC,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,LOC,O,O,O,O,O,O,O,O,ORG,O,O,O,O,O,O,O,O"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1412\n",
    "# 1528\n",
    "# 1529\n",
    "# 899\n",
    "test_df[test_df['Sentence #'] == 899]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.drop(test_df[test_df['Sentence #'] == 1529].index, inplace=True, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (514 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "899---514\n",
      "[101, 1011, 3010, 8982, 3222, 5710, 6067, 6617, 23534, 12731, 12171, 1059, 2243, 1061, 2099, 3283, 12731, 12171, 1059, 2243, 1061, 2099, 2000, 3058, 1061, 2099, 3283, 10500, 4724, 11387, 1012, 1016, 20024, 2683, 1012, 1017, 24841, 1012, 1019, 5786, 2581, 2620, 1012, 1023, 4583, 17914, 1012, 1014, 4241, 6824, 12904, 2620, 1012, 1023, 13092, 2629, 1012, 1014, 4008, 1012, 1017, 5986, 2629, 1012, 1017, 10114, 2683, 1012, 1020, 1051, 11149, 24921, 1012, 1019, 26871, 1012, 1020, 2861, 1012, 1023, 6109, 2581, 1012, 1017, 5388, 2487, 1012, 1016, 21569, 10550, 2549, 1012, 1014, 7287, 2549, 1012, 1022, 19289, 1012, 1014, 23254, 2487, 1012, 1018, 6347, 1012, 1015, 20926, 4008, 1012, 1020, 6564, 1012, 1017, 1016, 1012, 1017, 10715, 1012, 1016, 13285, 1012, 1016, 13109, 8528, 13913, 1012, 1016, 18596, 1012, 1023, 2403, 1012, 1023, 20304, 1012, 1018, 29327, 1012, 1023, 2064, 6030, 4185, 2575, 1012, 1020, 6146, 2683, 1012, 1018, 3438, 1012, 1019, 5774, 1012, 1014, 19936, 2581, 1012, 1020, 9781, 6535, 1012, 1020, 17867, 1012, 1019, 1023, 1012, 1018, 5345, 1012, 1021, 22898, 1012, 1014, 2561, 6255, 27531, 1012, 1022, 6255, 18827, 1012, 1022, 5786, 2683, 1012, 1022, 7558, 12376, 1012, 1016, 13285, 2581, 2683, 1012, 1020, 14338, 4968, 13406, 12731, 12171, 1059, 2243, 1061, 2102, 2094, 1061, 2099, 3283, 12731, 12171, 1059, 2243, 1061, 2102, 2094, 1061, 2099, 3283, 10500, 4229, 2581, 1012, 1018, 4805, 2581, 2581, 1012, 1022, 3429, 22275, 1012, 1020, 4583, 1012, 1016, 9800, 2683, 1012, 1021, 6391, 2575, 1012, 1015, 4241, 6824, 14378, 1012, 1014, 16528, 2629, 1012, 1023, 13092, 2692, 1012, 1020, 1018, 1012, 1020, 4293, 1012, 1022, 6421, 1012, 1017, 1051, 11149, 2871, 1012, 1014, 5179, 2487, 1012, 1014, 4464, 2487, 1012, 1023, 1018, 1012, 1022, 17332, 1012, 1020, 10630, 1012, 1014, 21569, 7287, 1012, 1022, 6036, 2509, 1012, 1018, 2753, 2575, 1012, 1014, 4466, 1012, 1016, 6365, 2487, 1012, 1014, 6275, 2575, 1012, 1020, 20926, 1018, 1012, 1015, 3438, 1012, 1021, 5401, 1012, 1023, 1017, 1012, 1014, 2184, 1012, 1021, 2324, 1012, 1023, 13109, 8528, 1021, 1012, 1016, 16666, 1012, 1015, 17825, 1012, 1021, 1015, 1012, 1015, 2570, 1012, 1016, 2321, 1012, 1021, 2064, 6030, 4700, 1012, 1015, 5818, 2620, 1012, 1015, 12104, 2629, 1012, 1019, 4805, 1012, 1021, 6486, 2549, 1012, 1023, 6445, 2475, 1012, 1014, 9781, 1018, 1012, 1018, 2321, 1012, 1015, 6584, 1012, 1014, 1014, 1012, 1020, 2570, 1012, 1015, 2340, 1012, 1015, 2561, 28004, 1012, 1014, 6205, 2581, 2575, 1012, 1015, 6282, 2620, 2620, 1012, 1016, 17943, 1012, 1016, 22904, 2575, 1012, 1014, 25143, 2575, 1012, 1021, 1999, 2804, 1010, 6747, 2710, 5393, 1996, 2206, 14338, 2000, 1996, 1057, 1012, 1055, 1012, 2090, 2257, 1998, 2244, 2727, 1010, 1999, 11000, 1024, 1051, 11149, 20926, 13109, 8528, 19763, 2094, 2064, 6030, 9781, 14338, 2756, 1010, 3263, 2459, 1010, 3263, 1021, 1010, 6352, 2531, 5354, 1010, 4278, 2095, 3283, 4700, 1010, 2199, 2484, 1010, 3998, 1022, 1010, 6352, 1022, 1010, 3263, 2260, 1010, 3263, 1006, 3190, 2739, 6155, 2243, 21036, 2871, 2620, 6584, 11387, 1007, 1011, 9986, 14117, 2102, 1011, 6396, 4168, 2595, 14085, 12617, 4515, 9249, 2896, 2006, 4633, 17680, 1012, 102]\n",
      "1411---771\n",
      "[101, 12436, 4014, 1010, 5169, 2727, 1011, 2260, 1011, 5718, 2308, 1005, 1055, 2088, 2452, 11869, 2044, 5095, 1005, 1055, 19448, 2679, 1024, 19448, 11869, 1015, 1012, 10645, 3900, 24681, 2121, 1006, 2762, 1007, 8380, 2685, 1016, 1012, 14916, 3686, 2175, 8454, 2818, 2140, 1006, 5118, 1007, 14078, 1017, 1012, 24348, 18318, 10484, 2102, 1006, 2605, 1007, 6564, 1018, 1012, 2566, 3490, 4571, 15536, 4059, 1006, 4701, 1007, 4293, 1019, 1012, 21372, 17924, 23736, 13871, 2368, 1006, 5288, 1007, 6353, 1020, 1012, 12512, 5292, 10600, 2140, 1006, 2762, 1007, 5764, 1021, 1012, 10481, 19734, 4757, 22792, 2121, 1006, 5118, 1007, 3515, 1022, 1012, 11163, 17920, 12849, 3367, 3678, 1006, 3304, 1007, 3438, 1023, 1012, 13749, 27614, 6330, 2928, 12377, 1006, 5120, 1007, 5388, 2184, 1027, 12756, 16216, 13465, 2100, 1006, 1057, 1012, 1055, 1012, 1007, 4868, 2184, 1027, 2162, 11872, 27838, 7770, 8337, 3900, 1006, 3607, 1007, 4868, 2184, 1027, 7701, 16137, 25389, 2050, 1006, 2605, 1007, 4868, 2410, 1027, 27263, 7875, 2080, 2395, 1006, 1057, 1012, 1055, 1012, 1007, 2753, 2410, 1027, 8852, 2666, 24253, 1006, 5118, 1007, 2753, 2321, 1012, 16925, 29536, 13512, 1006, 2762, 1007, 4700, 2385, 1012, 12170, 15599, 2050, 10730, 1006, 3304, 1007, 3429, 2459, 1012, 7632, 17920, 16216, 10623, 1006, 2762, 1007, 4413, 2324, 1012, 6437, 15993, 1006, 2762, 1007, 4229, 2539, 1027, 5736, 6393, 12110, 1006, 2710, 1007, 2603, 2539, 1027, 17917, 3388, 16695, 5580, 4509, 11444, 1006, 3607, 1007, 2603, 2539, 1027, 19723, 3170, 6187, 3567, 26745, 6784, 1006, 2605, 1007, 2603, 3452, 2308, 1005, 1055, 2088, 2452, 11869, 4177, 2044, 5095, 1005, 1055, 19448, 1998, 3565, 1043, 3837, 1024, 1015, 1012, 10645, 3900, 24681, 2121, 1006, 2762, 1007, 4601, 2549, 2685, 1016, 1012, 2566, 3490, 4571, 15536, 4059, 1006, 4701, 1007, 3486, 2509, 1017, 1012, 5342, 16216, 10623, 1006, 2762, 1007, 25113, 1018, 1012, 12918, 11333, 10143, 2121, 1006, 5118, 1007, 8380, 1019, 1012, 11163, 17920, 12849, 3367, 3678, 1006, 3304, 1007, 17403, 1020, 1012, 21372, 17924, 23736, 13871, 2368, 1006, 5288, 1007, 16710, 1021, 1012, 2162, 11872, 27838, 7770, 8337, 3900, 1006, 3607, 1007, 16528, 1022, 1027, 14916, 3686, 2175, 8454, 2818, 2140, 1006, 5118, 1007, 16333, 1022, 1027, 24348, 18318, 10484, 2102, 1006, 2605, 1007, 16333, 2184, 1012, 17917, 3388, 16695, 5580, 4509, 11444, 1006, 3607, 1007, 14989, 2340, 1012, 7701, 16137, 25389, 2050, 1006, 2605, 1007, 14506, 2260, 1012, 15555, 4012, 4502, 26977, 2072, 1006, 3304, 1007, 6036, 2410, 1012, 23508, 9413, 19646, 1006, 2762, 1007, 13285, 2403, 1012, 10481, 19734, 4757, 22792, 2121, 1006, 5118, 1007, 12963, 2321, 1012, 24471, 8337, 7570, 19146, 2102, 1006, 10307, 1007, 10715, 2385, 1027, 13479, 15544, 13910, 3917, 1006, 2047, 3414, 1007, 2531, 2385, 1027, 7842, 21114, 6090, 13471, 5498, 1006, 3304, 1007, 2531, 2324, 1012, 6437, 15993, 1006, 3304, 1007, 6227, 2539, 1012, 8852, 2666, 24253, 1006, 5118, 1007, 6486, 2322, 1012, 16925, 29536, 13512, 1006, 2762, 1007, 6146, 3565, 1043, 11869, 1024, 1015, 1012, 2566, 3490, 4571, 15536, 4059, 1006, 4701, 1007, 8380, 1016, 1012, 7632, 17920, 16216, 10623, 1006, 2762, 1007, 7558, 1017, 1012, 17917, 3388, 3122, 5580, 4509, 11444, 1006, 3607, 1007, 12457, 1018, 1012, 2162, 11872, 27838, 7770, 8337, 3900, 1006, 3607, 1007, 2531, 1019, 1012, 7701, 16137, 25389, 2050, 1006, 2605, 1007, 6445, 1020, 1012, 10645, 3900, 24681, 2121, 1006, 2762, 1007, 6356, 1021, 1012, 11163, 17920, 12849, 3367, 3678, 1006, 3304, 1007, 3515, 1022, 1012, 24348, 18318, 10484, 2102, 1006, 2605, 1007, 3438, 1023, 1012, 23508, 9413, 19646, 1006, 2762, 1007, 5388, 2184, 1012, 12918, 11333, 10143, 2121, 1006, 5118, 1007, 4749, 2340, 1012, 21372, 17924, 23736, 13871, 2368, 1006, 5288, 1007, 4724, 2260, 1027, 5506, 7770, 16908, 4590, 1011, 2621, 18900, 3334, 1006, 5288, 1007, 4413, 2260, 1027, 6437, 15993, 1006, 3304, 1007, 4413, 2260, 1027, 10645, 18428, 2532, 9535, 6132, 11631, 2078, 1006, 2762, 1007, 4413, 2321, 1012, 8852, 2666, 24253, 1006, 5118, 1007, 4464, 2385, 1012, 12203, 3775, 10711, 17488, 4135, 2480, 1006, 2605, 1007, 3943, 2459, 1012, 12170, 15599, 2050, 10730, 1006, 3304, 1007, 2382, 2324, 1027, 16925, 29536, 13512, 1006, 2762, 1007, 2756, 2324, 1027, 19887, 7987, 15937, 2226, 1006, 2605, 1007, 2756, 2322, 1012, 10481, 19734, 4757, 22792, 2121, 1006, 5118, 1007, 2676, 3842, 1005, 1055, 2452, 11869, 1024, 1015, 1012, 5118, 1015, 1010, 5989, 2509, 2685, 1016, 1012, 2762, 1015, 1010, 11502, 1017, 1012, 5288, 5989, 2475, 1018, 1012, 3304, 6070, 2581, 1019, 1012, 2605, 5594, 2509, 1020, 1012, 5120, 6356, 2575, 1021, 1012, 4701, 6163, 2509, 1022, 1012, 10307, 4724, 2475, 1023, 1012, 3607, 24841, 2184, 1012, 2142, 2163, 17943, 1011, 9986, 14117, 2102, 1011, 10348, 12701, 1011, 2308, 1005, 1055, 2088, 2452, 19448, 3463, 1012, 102]\n"
     ]
    }
   ],
   "source": [
    "test_df_output = model_test(test_df['Sentence'].values.tolist(), tokenizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1528</th>\n",
       "      <td>1528</td>\n",
       "      <td>1528</td>\n",
       "      <td>GLASGOW 1996 - 12 - 07 Scottish league standings after Saturday ' s matches ( tabulated - played , won , drawn , lost , goals for , goals against , points ) : Premier division Rangers 14 11 2 1 35 12 35 Celtic 14 8 3 3 32 15 27 Aberdeen 15 7 4 4 28 19 25 Hearts 15 5 6 4 18 19 21 Hibernian 15 5 3 7 16 25 18 Dundee United 15 4 5 6 17 17 17 Motherwell 15 4 5 6 17 23 17 Dunfermline 14 4 5 5 19 27 17 Raith 15 3 3 9 14 27 12 Kilmarnock 14 3 2 9 17 29 11 Division One St Johnstone 17 12 2 3 36 8 38 Falkirk 17 9 2 6 18 15 29 Airdrieonians 16 6 8 2 26 16 26 Dundee 16 7 5 4 12 8 26 Partick 16 6 6 4 23 16 24 St Mirren 16 7 2 7 22 21 23 Greenock Morton 16 6 4 6 17 16 22 Clydebank 16 4 2 10 11 25 14 Stirling 16 3 3 10 18 33 12 East Fife 14 1 4 9 10 35 7 Division Two Ayr 16 11 2 3 30 18 35 Livingston 16 10 4 2 27 13 34 Hamilton 15 9 4 2 31 11 31 Clyde 15 6 4 5 21 20 22 Queen of South 16 6 4 6 24 27 22 Stenhousemuir 15 4 5 6 18 12 17 Stranraer 15 5 2 8 13 21 17 Dumbarton 16 4 4 8 18 29 16 Brechin 16 3 6 7 14 20 15 Berwick 16 1 3 12 16 41 6 Division Three Montrose 17 9 3 5 30 25 30 Inverness Thistle 16 8 5 3 28 20 29 Ross County 17 8 3 6 27 23 27 Alloa 16 7 4 5 24 21 25 Cowdenbeath 15 7 3 5 22 16 24 Albion 16 6 6 4 21 17 24 Forfar 15 6 4 5 26 24 22 Queen ' s Park 16 3 5 8 20 30 14 Arbroath 16 2 6 8 12 23 12 East Stirling 16 2 5 9 14 25 11 - DOCSTART - SOCCER - ENGLISH LEAGUE STANDINGS .</td>\n",
       "      <td>LOC,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,ORG,O,O,O,O,O,O,O,ORG,O,O,O,O,O,O,O,ORG,O,O,O,O,O,O,O,ORG,O,O,O,O,O,O,O,ORG,O,O,O,O,O,O,O,ORG,ORG,O,O,O,O,O,O,O,ORG,O,O,O,O,O,O,O,ORG,O,O,O,O,O,O,O,ORG,O,O,O,O,O,O,O,ORG,O,O,O,O,O,O,O,O,O,ORG,ORG,O,O,O,O,O,O,O,ORG,O,O,O,O,O,O,O,ORG,O,O,O,O,O,O,O,ORG,O,O,O,O,O,O,O,ORG,O,O,O,O,O,O,O,ORG,ORG,O,O,O,O,O,O,O,ORG,ORG,O,O,O,O,O,O,O,ORG,O,O,O,O,O,O,O,ORG,O,O,O,O,O,O,O,ORG,ORG,O,O,O,O,O,O,O,O,O,ORG,O,O,O,O,O,O,O,ORG,O,O,O,O,O,O,O,ORG,O,O,O,O,O,O,O,ORG,O,O,O,O,O,O,O,ORG,ORG,ORG,O,O,O,O,O,O,O,ORG,O,O,O,O,O,O,O,ORG,O,O,O,O,O,O,O,ORG,O,O,O,O,O,O,O,ORG,O,O,O,O,O,O,O,ORG,O,O,O,O,O,O,O,O,O,ORG,O,O,O,O,O,O,O,ORG,ORG,O,O,O,O,O,O,O,ORG,ORG,O,O,O,O,O,O,O,ORG,O,O,O,O,O,O,O,ORG,O,O,O,O,O,O,O,ORG,O,O,O,O,O,O,O,ORG,O,O,O,O,O,O,O,ORG,ORG,ORG,ORG,O,O,O,O,O,O,O,ORG,O,O,O,O,O,O,O,ORG,ORG,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  Sentence #                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Sentence                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Tag\n",
       "1528   1528        1528  GLASGOW 1996 - 12 - 07 Scottish league standings after Saturday ' s matches ( tabulated - played , won , drawn , lost , goals for , goals against , points ) : Premier division Rangers 14 11 2 1 35 12 35 Celtic 14 8 3 3 32 15 27 Aberdeen 15 7 4 4 28 19 25 Hearts 15 5 6 4 18 19 21 Hibernian 15 5 3 7 16 25 18 Dundee United 15 4 5 6 17 17 17 Motherwell 15 4 5 6 17 23 17 Dunfermline 14 4 5 5 19 27 17 Raith 15 3 3 9 14 27 12 Kilmarnock 14 3 2 9 17 29 11 Division One St Johnstone 17 12 2 3 36 8 38 Falkirk 17 9 2 6 18 15 29 Airdrieonians 16 6 8 2 26 16 26 Dundee 16 7 5 4 12 8 26 Partick 16 6 6 4 23 16 24 St Mirren 16 7 2 7 22 21 23 Greenock Morton 16 6 4 6 17 16 22 Clydebank 16 4 2 10 11 25 14 Stirling 16 3 3 10 18 33 12 East Fife 14 1 4 9 10 35 7 Division Two Ayr 16 11 2 3 30 18 35 Livingston 16 10 4 2 27 13 34 Hamilton 15 9 4 2 31 11 31 Clyde 15 6 4 5 21 20 22 Queen of South 16 6 4 6 24 27 22 Stenhousemuir 15 4 5 6 18 12 17 Stranraer 15 5 2 8 13 21 17 Dumbarton 16 4 4 8 18 29 16 Brechin 16 3 6 7 14 20 15 Berwick 16 1 3 12 16 41 6 Division Three Montrose 17 9 3 5 30 25 30 Inverness Thistle 16 8 5 3 28 20 29 Ross County 17 8 3 6 27 23 27 Alloa 16 7 4 5 24 21 25 Cowdenbeath 15 7 3 5 22 16 24 Albion 16 6 6 4 21 17 24 Forfar 15 6 4 5 26 24 22 Queen ' s Park 16 3 5 8 20 30 14 Arbroath 16 2 6 8 12 23 12 East Stirling 16 2 5 9 14 25 11 - DOCSTART - SOCCER - ENGLISH LEAGUE STANDINGS .  LOC,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,ORG,O,O,O,O,O,O,O,ORG,O,O,O,O,O,O,O,ORG,O,O,O,O,O,O,O,ORG,O,O,O,O,O,O,O,ORG,O,O,O,O,O,O,O,ORG,ORG,O,O,O,O,O,O,O,ORG,O,O,O,O,O,O,O,ORG,O,O,O,O,O,O,O,ORG,O,O,O,O,O,O,O,ORG,O,O,O,O,O,O,O,O,O,ORG,ORG,O,O,O,O,O,O,O,ORG,O,O,O,O,O,O,O,ORG,O,O,O,O,O,O,O,ORG,O,O,O,O,O,O,O,ORG,O,O,O,O,O,O,O,ORG,ORG,O,O,O,O,O,O,O,ORG,ORG,O,O,O,O,O,O,O,ORG,O,O,O,O,O,O,O,ORG,O,O,O,O,O,O,O,ORG,ORG,O,O,O,O,O,O,O,O,O,ORG,O,O,O,O,O,O,O,ORG,O,O,O,O,O,O,O,ORG,O,O,O,O,O,O,O,ORG,O,O,O,O,O,O,O,ORG,ORG,ORG,O,O,O,O,O,O,O,ORG,O,O,O,O,O,O,O,ORG,O,O,O,O,O,O,O,ORG,O,O,O,O,O,O,O,ORG,O,O,O,O,O,O,O,ORG,O,O,O,O,O,O,O,O,O,ORG,O,O,O,O,O,O,O,ORG,ORG,O,O,O,O,O,O,O,ORG,ORG,O,O,O,O,O,O,O,ORG,O,O,O,O,O,O,O,ORG,O,O,O,O,O,O,O,ORG,O,O,O,O,O,O,O,ORG,O,O,O,O,O,O,O,ORG,ORG,ORG,ORG,O,O,O,O,O,O,O,ORG,O,O,O,O,O,O,O,ORG,ORG,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[test_df['Sentence #'] == 1528]\n",
    "#899\n",
    "#1412\n",
    "#1529\n",
    "#1528"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = df[(df['Sentence #'] == 1529)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "810"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(i, inplace=True, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = prepare_model_output(test_df_output, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_no</th>\n",
       "      <th>labels</th>\n",
       "      <th>token</th>\n",
       "      <th>label_asr</th>\n",
       "      <th>token_asr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50825</th>\n",
       "      <td>1622</td>\n",
       "      <td>O</td>\n",
       "      <td>younger</td>\n",
       "      <td>O</td>\n",
       "      <td>by</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50826</th>\n",
       "      <td>1622</td>\n",
       "      <td>O</td>\n",
       "      <td>brother</td>\n",
       "      <td>O</td>\n",
       "      <td>his</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50827</th>\n",
       "      <td>1622</td>\n",
       "      <td>O</td>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "      <td>opponent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50828</th>\n",
       "      <td>1622</td>\n",
       "      <td>PER</td>\n",
       "      <td>bobby</td>\n",
       "      <td>O</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50829</th>\n",
       "      <td>1622</td>\n",
       "      <td>O</td>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "      <td>said</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentence_no labels    token label_asr token_asr\n",
       "50825        1622      O  younger         O        by\n",
       "50826        1622      O  brother         O       his\n",
       "50827        1622      O        ,         O  opponent\n",
       "50828        1622    PER    bobby         O         ,\n",
       "50829        1622      O        .         O      said"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['O', 'LOC', 'PER', 'ORG'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['label_asr'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_test = test_df.groupby(\"sentence_no\")\n",
    "test = pd.DataFrame({\"model_tag\": g_test.apply(lambda sdf: sdf.labels.values.tolist()),\n",
    "                       \"asr_tag\": g_test.apply(lambda sdf: sdf.label_asr.values.tolist())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['asr_sentence_no'] = test.index\n",
    "test[[\"asr_sentence_no\"]] = test[[\"asr_sentence_no\"]].apply(pd.to_numeric)\n",
    "test.sort_values('asr_sentence_no', inplace=True)\n",
    "test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_tag</th>\n",
       "      <th>asr_tag</th>\n",
       "      <th>asr_sentence_no</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[O, O, LOC, O, O, O, O, LOC, O, O, O, O]</td>\n",
       "      <td>[O, O, LOC, O, O, O, O, PER, O, O, O, O]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[PER, PER, ORG, ORG, ORG, O, LOC, LOC, LOC, O, O, O, O, O, LOC, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, LOC, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[PER, PER, LOC, LOC, LOC, O, LOC, LOC, LOC, O, O, O, O, O, LOC, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, LOC, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[O, LOC, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, LOC, O]</td>\n",
       "      <td>[O, LOC, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, LOC, O]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[LOC, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ORG, O, PER, PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[LOC, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, PER, PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[PER, PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[PER, PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                         model_tag                                                                                                                                          asr_tag  asr_sentence_no\n",
       "0                                                                                                         [O, O, LOC, O, O, O, O, LOC, O, O, O, O]                                                                                                         [O, O, LOC, O, O, O, O, PER, O, O, O, O]                0\n",
       "1  [PER, PER, ORG, ORG, ORG, O, LOC, LOC, LOC, O, O, O, O, O, LOC, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, LOC, O, O, O, O, O, O, O, O, O]  [PER, PER, LOC, LOC, LOC, O, LOC, LOC, LOC, O, O, O, O, O, LOC, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, LOC, O, O, O, O, O, O, O, O, O]                1\n",
       "2                                                            [O, LOC, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, LOC, O]                                                            [O, LOC, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, LOC, O]                2\n",
       "3           [LOC, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ORG, O, PER, PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]             [LOC, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, PER, PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]                3\n",
       "4                                                                        [PER, PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]                                                                        [PER, PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]                4"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8634074365532166\n",
      "F1 Score:  0.4855651105651106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shahzainmehboob/opt/anaconda3/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: LOC seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/Users/shahzainmehboob/opt/anaconda3/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PER seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/Users/shahzainmehboob/opt/anaconda3/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ORG seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \" , accuracy_score(test['model_tag'].values.tolist(), test['asr_tag'].values.tolist()))\n",
    "print(\"F1 Score: \",f1_score(test['model_tag'].values.tolist(), test['asr_tag'].values.tolist()))\n",
    "#statistics(test_df, ['PER', 'ORG', 'LOC', 'O'])\n",
    "#0.7758389261744967 without punctuation\n",
    "#0.676056338028169 with punctuation 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_for_analysis(test_df, original_data_path):\n",
    "    g_asr = test_df.groupby(\"sentence_no\")\n",
    "    asr_df = pd.DataFrame({'Sentence': g_asr.apply(lambda sdf: \" \".join(map(str,sdf.token))),\n",
    "                      'Tag': g_asr.apply(lambda sdf: \",\".join(sdf.labels))})\n",
    "    asr_df['asr_sentence_no'] = asr_df.index\n",
    "    asr_df[[\"asr_sentence_no\"]] = asr_df[[\"asr_sentence_no\"]].apply(pd.to_numeric)\n",
    "    asr_df.sort_values('asr_sentence_no', inplace=True)\n",
    "    asr_df.reset_index(drop=True, inplace=True)\n",
    "    original = pd.read_csv(original_data_path)\n",
    "    original.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "    original = original[:7851]\n",
    "    g_original = original.groupby(\"Sentence #\")\n",
    "    original_df = pd.DataFrame({'Sentence': g_original.apply(lambda sdf: \" \".join(map(str,sdf.Word))),\n",
    "                      'Tag': g_original.apply(lambda sdf: \",\".join(sdf.Tag))})\n",
    "    original_df.reset_index(inplace=True)\n",
    "    combined_df = pd.DataFrame({\"original_sentence\": original_df['Sentence'].str.lower(),\n",
    "                           \"original_tags\": original_df['Tag'], \n",
    "                           \"asr_sentence\": asr_df['Sentence'],\n",
    "                           \"asr_tags\": asr_df['Tag']})\n",
    "    return asr_df, combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pattern_finding(tag, combined_df):\n",
    "#tag = \"PER\"\n",
    "    analysis = []\n",
    "    for i in range(0, len(combined_df), 1):\n",
    "        sample = combined_df.loc[[i]]\n",
    "        for original_sentence, asr_sentence, original_tag, asr_tag in zip(sample['original_sentence'].values.tolist(),\n",
    "                                                                          sample['asr_sentence'].values.tolist(),\n",
    "                                                                          sample['original_tags'].values.tolist(),\n",
    "                                                                          sample['asr_tags'].values.tolist()):\n",
    "            original_tag_token = np.array(original_tag.split(\",\"))\n",
    "            asr_tag_token = np.array(asr_tag.split(\",\"))\n",
    "            original_label = np.array(original_sentence.lower().split())\n",
    "            asr_label = np.array(asr_sentence.lower().split())\n",
    "\n",
    "            if tag in original_tag_token:\n",
    "                original_tag_ind = [index for index, element in enumerate(original_tag_token) if\n",
    "                                    original_tag_token[index] == tag]\n",
    "                if tag in asr_tag_token:\n",
    "                    asr_tag_ind = [index for index, element in enumerate(asr_tag_token) if\n",
    "                                       asr_tag_token[index] == tag]\n",
    "                    \n",
    "                    asr_tokens = []\n",
    "                    original_tokens = []\n",
    "                    errors = []\n",
    "                        # Sweynheim pannartz\n",
    "                        # Swain heim pannartz\n",
    "                    for ind in original_tag_ind:\n",
    "                        original_entity = original_label[ind]\n",
    "                        asr_entity = difflib.get_close_matches(original_entity, asr_label[asr_tag_ind])\n",
    "                        if len(asr_entity) > 0:\n",
    "                            asr_entity = asr_entity[0]\n",
    "                            error = (1 - (Levenshtein.distance(original_entity, asr_entity) / max(len(original_entity), len(asr_entity)))) * 100\n",
    "                            if error >= 50:\n",
    "                                asr_tokens.append(asr_entity)\n",
    "                                original_tokens.append(original_entity)\n",
    "                                errors.append(error)\n",
    "                            else:\n",
    "                                asr_tokens.append(\"None\")\n",
    "                                original_tokens.append(original_entity)\n",
    "                                errors.append(0.0)\n",
    "                        else:\n",
    "                            asr_tokens.append(\"None\")\n",
    "                            original_tokens.append(original_entity)\n",
    "                            errors.append(0.0)\n",
    "                    analysis.append((i, original_tokens, asr_tokens, errors, np.mean(errors), True))\n",
    "                else:\n",
    "                    check = []\n",
    "                    o_label = original_label[original_tag_ind]\n",
    "                    for lab in o_label:\n",
    "                        j = 0\n",
    "                        for asr_lab in asr_label:\n",
    "                            local_error = (1 - (Levenshtein.distance(lab, asr_lab) / max(len(lab), len(asr_lab)))) * 100\n",
    "                            if local_error >= 50.0:\n",
    "                                check.append(j)\n",
    "                            j = j + 1\n",
    "                    if len(check) > 0:\n",
    "                        asr_tokens = []\n",
    "                        original_tokens = []\n",
    "                        errors = []\n",
    "                        for ind in original_tag_ind:\n",
    "                            original_entity = original_label[ind]\n",
    "                            asr_entity = difflib.get_close_matches(original_entity, asr_label[check])\n",
    "                            if len(asr_entity) > 0:\n",
    "                                asr_entity = asr_entity[0]\n",
    "                                error = (1 - (Levenshtein.distance(original_entity, asr_entity) / max(\n",
    "                                len(original_entity), len(asr_entity)))) * 100\n",
    "                                asr_tokens.append(asr_entity)\n",
    "                                original_tokens.append(original_entity)\n",
    "                                errors.append(error)\n",
    "                            else:\n",
    "                                asr_tokens.append(\"None\")\n",
    "                                original_tokens.append(original_entity)\n",
    "                                errors.append(0.0)\n",
    "                        analysis.append((i, original_tokens, asr_tokens, errors, np.mean(errors), False))\n",
    "                    else:\n",
    "                        analysis.append((i, original_label[original_tag_ind], [\"None\"], [0.0], 0.0, False))\n",
    "    return analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asr_df, combined_df = prepare_data_for_analysis(test_df, 'unprocessed_sampled_original.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df = pd.DataFrame(pattern_finding(\"PER\", combined_df), columns=['Sample #', 'Original', 'ASR', 'Lavenstein', 'Lavenstein Mean', 'Flag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "analysis_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(analysis_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([100.0,100.0]) == 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_asr_found_complete = analysis_df[(analysis_df['Flag'] == True) & (analysis_df['Lavenstein Mean'] == 100.0)]\n",
    "orig_asr_found_complete_per = (len(orig_asr_found_complete) / len(analysis_df)) * 100\n",
    "print(orig_asr_found_complete_per)\n",
    "orig_asr_found_complete.head()\n",
    "print(len(orig_asr_found_complete))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_asr_found_complete.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_asr_found = analysis_df[(analysis_df['Flag'] == True) & (analysis_df['Lavenstein Mean'] < 100.0) & (analysis_df['Lavenstein Mean'] >= 0.0)]\n",
    "orig_asr_found_per = (len(orig_asr_found) / len(analysis_df)) * 100\n",
    "print(orig_asr_found_per)\n",
    "print(len(orig_asr_found))\n",
    "orig_asr_found.head()\n",
    "#40.88050314465409\n",
    "#65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_asr_similar = analysis_df[(analysis_df['Flag'] == False) & (analysis_df['Lavenstein Mean'] <= 100.0) & (analysis_df['Lavenstein Mean'] > 0.0)]\n",
    "orig_asr_similar_per = (len(orig_asr_similar) / len(analysis_df)) * 100\n",
    "print(orig_asr_similar_per)\n",
    "orig_asr_similar.head()\n",
    "print(len(orig_asr_similar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_asr_similar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "orig_asr_nofound = analysis_df[(analysis_df['Flag'] == False) & (analysis_df['Lavenstein Mean'] <= 0.0)]\n",
    "orig_asr_nofound_per = (len(orig_asr_nofound) / len(analysis_df))*100\n",
    "print(orig_asr_nofound_per)\n",
    "orig_asr_nofound.head()\n",
    "print(len(orig_asr_nofound))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_asr_nofound.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[orig_asr_found_complete_per, orig_asr_found_per, orig_asr_similar_per, orig_asr_nofound_per]\n",
    "#[45.56962025316456, 43.67088607594937, 9.49367088607595, 1.2658227848101267]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[len(orig_asr_found_complete), len(orig_asr_found), len(orig_asr_similar), len(orig_asr_nofound)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abx = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.loc[orig_asr_similar['Sample #'].values.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_org = ['chiswick press in 1844 revived castle on stops , printing for measures the diary of lady willoughby .',\n",
    " \"the position of our society that don ' t work of utility might be also a work of art , if we care to make it so .\",\n",
    " 'the chronicles of nougat , volume to . arthur griffiths . section for \" new gate down to 1818 .',\n",
    " \"full details of the arrangements are to be found in mr . neil ' s \\\" state of prisons in england , scotland , and wales , \\\" published in 1812 .\",\n",
    " 'alfred the great established the court baron , the hundred court , and the county court , which among other matters entertain please for debt .',\n",
    " \"lake county court was the sheriff ' s , who said they ' re surrounded by the bishop and the magnets of the county\",\n",
    " \"but as time passed , difficulties and delays in obtaining judgment led to the removal of causes to the great court of king ' s bench ,\",\n",
    " 'so much inconvenience ensued , that in 1518 the corporation obtained from parliament and act empowering to alderman',\n",
    " 'four common councilman to hold courts of requests , or courts of conscience , to hear and determine all causes of death',\n",
    " 'other cases are recorded elsewhere , that the gilts 1st street concert , where in 1805 mister . kneeled found a man named william grant',\n",
    " 'mr buxton . in his \" inquiry into the system of prison discipline , \"',\n",
    " 'to those in other london prisons , for new gate was not the only place of durance for these unfortunate people . there were also the kings bench ,',\n",
    " 'the fleet , and the marshalsea prison especially devoted to them ,',\n",
    " 'the sale of spirits was forbidden , but june could always be had at the whistling shops , where it was known as moonshine , sky blue ,',\n",
    " 'the fleet , which stood in farrington street ,',\n",
    " 'the warden of the fleet at the commencement of the 18th century , are too well known to need more than a passing reference .',\n",
    " 'the committee on jails reported , that quote , although the house of the warden looked into the court ,',\n",
    " 'and came under the strong animated version of the jail committee of 1729 ,',\n",
    " 'the lord steward of the household , the stewart and officers of the marshalsea court , and others .',\n",
    " 'comforters of ludgate , giltspur street , and the borough where discontinued as debtors \\' prisons ( as was newgate also )',\n",
    " \"clergyman , proctor ' s , attorneys , and persons specially selected by the corporation .\",\n",
    " 'at one time the ludgate debtors , accompanied by the keeper ,',\n",
    " \"spruce street compton received sheriff ' s debtors , also felons , vagrants , and knight charges .\",\n",
    " 'it was generally crowded , as debtors who would have gone to the poultry copter we sent to giltspur street when the former was condemned as unfit to receive prisoners .',\n",
    " \"the borough compter was in a disgraceful state to the last . the men ' s ward had an earth or rather a mud , floor ,\",\n",
    " \"notably as when numbers filled new gate in anticipation of lord reds dale ' s bill for insolvent debtors ,\",\n",
    " 'is gradually was forced upon the consciousness of the corporation ,',\n",
    " 'bypass now to the criminal side of newgate , which consisted of the six quarters or yards already enumerated and describe .',\n",
    " 'it was particularly recommended by the committee on jails in 1814',\n",
    " \"send mr . addison , keeper of new gate , to make a visitation of the jail ' s supposed to be the best managed , including those of petworth and gloucester ,\",\n",
    " 'the committee did not deny the superior advantages offered by such prisons as gloucester and petworth ,',\n",
    " 'the committee does not seem to have yet understood that new gate could be only and properly replaced',\n",
    " 'buy a new jail built on the outskirts , as holloway eventually was , and committed itself to be altogether counter',\n",
    " \"i ' m checked in its efforts towards reform by the prohibitory costliness of the land about nougat .\",\n",
    " 'why not relieving you gate more largely upon the superior accommodation which build bank offer ?',\n",
    " 'chronicles of new gate , volume 2 . by arthur griffith . section 7 : the beginnings of prison reform .',\n",
    " 'i have shown in a previous chapter what new gate was at this , despite a vast expenditure and boasted efforts to introduce reforms .',\n",
    " 'one of the moving spirits was the honorable h . g bennett , auntie , whose vigorous protests against the lamentable condition of newgate have already been recorded .',\n",
    " 'as the prison discipline society pertinently observed in a report dated 1820 ,',\n",
    " 'the chronicles of nougat , volume 2 . by arthur griffith . section 8 : the beginnings of prison reform .',\n",
    " 'newgate prisoners were the victims to another most objectionable practice which obtained all over london .',\n",
    " 'the society for the improvement of prison discipline was taxed with a desire to introduce a system',\n",
    " 'an imputation which the society indignantly and very justly repudiated , the statement being , as they said ,',\n",
    " 'among those from the society found a raid against it was sidney smith ,',\n",
    " 'admitting the good intentions of the society , he condemned there ultra humanitarianism as misplaced ,',\n",
    " 'he took exception to various of the proposals of the society . he thought they linked too much to a system of indulgences and education in jails .',\n",
    " \"society pursuit it ' s laudable undertaking with a remarkable energy and great singleness of purpose .\",\n",
    " 'a much - needed and , according to our ideas , indispensable reform , already initiated by the ladies \\' committee at newgate .',\n",
    " 'brandon moral and religious duty , and which after a time sought to provide them with suitable situations , was supported entirely out of the funds of the society ,',\n",
    " 'another point to which the society devoted infinite was the preparation of plans for the guidance of architects in the construction of prisons .',\n",
    " 'a very valuable volume published by the society',\n",
    " 'was introduced as early as 1790 by mr . blackburn',\n",
    " 'the society did not limit its remarks to the description of what had already been done',\n",
    " 'the prison society reproves the misdirected efforts of ambitious architect , to buy a lavish an improvident expenditure of public money',\n",
    " \"these are principles fully recognized now - a - days , and it may fairly be conceded that the prison discipline society ' s ideal\",\n",
    " 'after a few years of active exertion the society was rewarded by fresh legislation .',\n",
    " 'to its efforts , and their effect upon parliament and the public mind , we must attribute the new jail acts of for george the 4th',\n",
    " 'the promulgation of these to jail acts strengthen the hands of the prison discipline society enormously .',\n",
    " 'the society did not shrink from its self - imposed duty , but continued year after year , with unflagging energy and unflinching spirit , to watch closely',\n",
    " 'upon these and the private visitations made by various members of the society obtained effects ,',\n",
    " 'four years later the prison society reported',\n",
    " 'i just chillin by the report of the commissioners to inquire into the state of the municipal corporations in 1835 .',\n",
    " 'kidderminster had a prison , one dance chill room ,',\n",
    " 'in 1827 the society was compelled to report that \" no material change has taken place in newgate since the passing of the prison laws ,',\n",
    " 'the prison society did not relax its efforts as time passed , but its leading members had other and more pressing claims upon their energies .',\n",
    " 'this committee anniversary strongly upon the system in force at the metropolitan jails , and more especially upon the condition of nougat',\n",
    " 'mister . samuel hoare was examined by this committee',\n",
    " 'i stated that in his opinion new gate , as the common jail of middlesex , was wholly inadequate to the proper confinement of its prisoners .',\n",
    " 'the committee was appointed , under the presidency of the duke of richmond',\n",
    " 'the whole question was again dealt with in lord john russell bill for the reform of the municipal corporations , and with a more liberal election of town councillors ,',\n",
    " 'newgate has remained rather in the background while the whole of the jails as a body wear under discussion .',\n",
    " 'william crawford had been one of the promoters and managers of the philanthropic societies farm school .',\n",
    " 'unlimited it to newgate alone . newgate indeed became the sole seam of their first report .',\n",
    " 'it was no longer the faintest possible excuse for overcrowding . the numbers now committed to newgate',\n",
    " 'temporary fences of the most varying description by the central criminal court .',\n",
    " 'but incredible as it may appear , the authorities of newgate declined to avail themselves of the advantages offered them ,',\n",
    " 'famous female side , where the ladies \\' association still reigned supreme , more system and a greater semblance of decorum was maintained .']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loc = ['printed very few books in this type 3 only but in their very first book syndrome , beginning with the year 1468 ,',\n",
    " 'the chronicles of nougat , volume to . arthur griffiths . section for : new gate down to 1818 .',\n",
    " 'seldom let a session go by without visiting you gate .',\n",
    " 'returns laid before the house of commons showed that 6439 persons have been committed to nougat',\n",
    " 'there was in the city road a temporary bar , with a collector of tolls who was sometimes on the spot and sometimes not .',\n",
    " 'the best , or at least the most influential prisoners , god lodging in the statehouse , which contained \" eight large handsome rooms . \"',\n",
    " 'in consequence of these disclosures , bambridge and hugging , his predecessor in the office , or committed to newgate ,',\n",
    " 'senators were rather better at the marshalsea ,',\n",
    " 'is bequest , which was charged upon his manner at goering , auxins , and hence called the oxford charity ,',\n",
    " 'the chronicles of nougat , volume 2 . by arthur griffiths . section v : newgate down to 18 18 , part 2 .',\n",
    " 'notes for street , and the poultry , or about 476 and all .',\n",
    " 'such as measures . virtual corn hill and messrs . leach and dollemore of ludgate hill .',\n",
    " 'it was very desirable that there should be a more speedy removal of transports from you gate to the ships .',\n",
    " 'specify more particularly one or two of the worst , it may be mentioned that in the boro comforter',\n",
    " 'the system not adopted generally till nearly half a century later had already prevail that bill chester .',\n",
    " 'for the reception of deserving cases discharged from prison . the governor a new gate and other metropolitan prisons had orders of admission to this refuge',\n",
    " 'this committee anniversary strongly upon the system in force at the metropolitan jails , and more especially upon the condition of nougat',\n",
    " 'he blamed the construction of new gate for the neglect of classification , and was yet compelled to confess that he had made no attempt whatever to carry it out .']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_per = ['especially as regards to lower - case letters and type very similar was used during the next 15 or 20 years not only by chauffeur ,',\n",
    " 'about the same year mental in at strasburg began to print in a type which is distinctly roman',\n",
    " 'and though the famous family of aldis restored its technical excellence , rejecting battered letters ,',\n",
    " 'most of caxton zone types of an earlier character ,',\n",
    " 'now come into general use that are obviously a great improvement on the ordinary \" modern style \" and use in england , which is in fact the bodony type',\n",
    " 'on the top of the jail , continues neeld arawatch - house and a century - box where two or more guards , with dogs and firearms ,',\n",
    " 'these courts were extended to centuries later to several large provincial towns , and all were in full activity when nield road ,',\n",
    " \"he had been in the employ of a corn - chandler at islington , and went into london with his master ' s cart and horse .\",\n",
    " \"neil ' s gives a list of the various items charged upon a debt of 10 , lb which included instructions to sue ,\",\n",
    " 'shameful malpractices of bambridge ,',\n",
    " 'the lord steward of the household , the stewart and officers of the marshalsea court , and others .',\n",
    " 'if they happened to be in funds - - among whom was the marquis of slego in 1811 .',\n",
    " 'mister . kneeled , a second howard ,',\n",
    " 'the most important jail active satterlee , however , was the 24 george the third . c . 54 , s . 4 ( 1784 )',\n",
    " 'classification was insisted upon , in the manner laid down by the 24 george the third . cat . 54 ,',\n",
    " 'which became the four george the 4th . tap . 64 , said that he had abstained from legislating for these small jurisdictions \" on mature deliberation . \"',\n",
    " 'nothing was more prominently brought out by the inspectors and the inefficiency of the governor at that time , mister . co .',\n",
    " 'watkins \\' disney - joint is very severely injured']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python3\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = [orig_asr_found_complete_per, orig_asr_found_per, orig_asr_similar_per, orig_asr_nofound_per]\n",
    "plt.bar(['Correctly Identified', 'Identified with missing entities', 'Similar tag but not identified', 'No Tag identification'], data)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pattern_analysis(sample_df, combined_df):\n",
    "    ind = np.array(sample_df['Sample #'].values.tolist())\n",
    "    df = combined_df.loc[ind]\n",
    "    df.insert(2,'Original',sample_df['Original'].values.tolist())\n",
    "    df.insert(5,'ASR',sample_df['ASR'].values.tolist())\n",
    "    df.drop(['original_tags', 'asr_tags'], axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_pattern = pattern_analysis(orig_asr_similar, combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(error_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_pattern.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_sampling(df):\n",
    "    i = 0\n",
    "    equal_length_samples = []\n",
    "    variable_length_samples = []\n",
    "    for sample, original, asr in zip(df.index, \n",
    "                                     df['Original'],\n",
    "                                     df['ASR']):\n",
    "        if len(original) == len(asr):\n",
    "            equal_length_samples.append(sample)\n",
    "        else:\n",
    "            variable_length_samples.append(sample)\n",
    "    equal_length_samples.sort()\n",
    "    variable_length_samples.sort()\n",
    "    equal_length_samples_df = df.loc[equal_length_samples]\n",
    "    variable_length_samples_df = df.loc[variable_length_samples]\n",
    "    return equal_length_samples_df, variable_length_samples_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equal_length_words_samples_df, variable_length_words_samples_df = error_sampling(error_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(equal_length_words_samples_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equal_length_words_samples_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(variable_length_words_samples_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "variable_length_words_samples_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equal_words_simulation(sampled_df):\n",
    "    simulated_asr = []\n",
    "    for sample, original_sentence, asr_sentence, original, asr in zip(sampled_df.index,\n",
    "                                     sampled_df['original_sentence'],\n",
    "                                     sampled_df['asr_sentence'],\n",
    "                                     sampled_df['Original'],\n",
    "                                     sampled_df['ASR']):\n",
    "\n",
    "        for x,y in zip(original, asr):\n",
    "            #original_words.append(x)\n",
    "            #asr_words.append(y)\n",
    "            if y in asr_sentence:\n",
    "                asr_sentence = asr_sentence.replace(y, x)\n",
    "            \n",
    "        simulated_asr.append((sample, asr_sentence))\n",
    "    simulated_asr_df = pd.DataFrame(simulated_asr)\n",
    "    return simulated_asr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variable_words_simulation(df):\n",
    "    check = []\n",
    "    for sample, original_sentence, asr_sentence, original_tag, asr_tag in zip(\n",
    "            df.index,\n",
    "            df['original_sentence'].values.tolist(),\n",
    "            df['asr_sentence'].values.tolist(),\n",
    "            df['Original'].values.tolist(),\n",
    "            df['ASR'].values.tolist()):\n",
    "\n",
    "        original_label = np.array(original_sentence.split())\n",
    "        asr_label = np.array(asr_sentence.split())\n",
    "        original_tag_ind = [index for index, element in enumerate(original_label) if original_label[index] in original_tag]\n",
    "        asr_tag_ind = [index for index, element in enumerate(asr_label) if asr_label[index] in asr_tag]\n",
    "        original_bigrams = []\n",
    "        asr_bigrams = []\n",
    "        o_label = original_label[original_tag_ind]\n",
    "        for lab in original_tag:\n",
    "            for asr_lab in asr_tag:\n",
    "                local_error = (1 - (Levenshtein.distance(lab, asr_lab) / max(len(lab), len(asr_lab)))) * 100\n",
    "                if local_error >= 50.0:\n",
    "                    asr_sentence = asr_sentence.replace(asr_lab, lab)\n",
    "        check.append((sample, asr_sentence))\n",
    "    new_asr = pd.DataFrame(check)\n",
    "    return new_asr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_df(asr_df, simulated_df):\n",
    "    asr_df.loc[simulated_df[0].values.tolist(), 'Sentence'] = simulated_df[1].values.tolist()\n",
    "    return asr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_asr_df = equal_words_simulation(equal_length_words_samples_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "simulated_asr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asr_df.loc[simulated_asr_df[0].values.tolist(), 'Sentence'] = test_org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asr_df = update_df(asr_df, simulated_asr_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simulated_asr_df = variable_words_simulation(variable_length_words_samples_df)\n",
    "#simulated_asr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#asr_df = update_df(asr_df, simulated_asr_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = model_test(asr_df['Sentence'].values.tolist(), tokenizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexNames = test_df[test_df['token'] == \"[CLS]\" ].index\n",
    "test_df.drop(indexNames, inplace=True)\n",
    "indexNames = test_df[test_df['token'] == \"[SEP]\" ].index\n",
    "test_df.drop(indexNames, inplace=True)\n",
    "test_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_df = prepare_model_output(test_df, new_df)\n",
    "test_df = prepare_model_output(test_df, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['labels'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_test = test_df.groupby(\"sentence_no\")\n",
    "test = pd.DataFrame({\"model_tag\": g_test.apply(lambda sdf: sdf.labels.values.tolist()),\n",
    "                       \"asr_tag\": g_test.apply(lambda sdf: sdf.label_asr.values.tolist())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['asr_sentence_no'] = test.index\n",
    "test[[\"asr_sentence_no\"]] = test[[\"asr_sentence_no\"]].apply(pd.to_numeric)\n",
    "test.sort_values('asr_sentence_no', inplace=True)\n",
    "test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy: \" , accuracy_score(test['model_tag'].values.tolist(), test['asr_tag'].values.tolist()))\n",
    "print(\"F1 Score: \",f1_score(test['model_tag'].values.tolist(), test['asr_tag'].values.tolist()))\n",
    "#statistics(test_df, ['PER', 'ORG', 'LOC', 'O'])\n",
    "#0.7758389261744967 without punctuation\n",
    "#0.676056338028169 with punctuation 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asr_df, combined_df = prepare_data_for_analysis(test_df, 'unprocessed_sampled_original.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df = pd.DataFrame(pattern_finding(\"ORG\", combined_df), columns=['Sample #', 'Original', 'ASR', 'Lavenstein','Lavenstein Mean', 'Flag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(analysis_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_asr_found_complete = analysis_df[(analysis_df['Flag'] == True) & (analysis_df['Lavenstein Mean'] == 100.0)]\n",
    "orig_asr_found_complete_per = (len(orig_asr_found_complete) / len(analysis_df)) * 100\n",
    "print(orig_asr_found_complete_per)\n",
    "orig_asr_found_complete.head()\n",
    "print(len(orig_asr_found_complete))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_asr_found = analysis_df[(analysis_df['Flag'] == True) & (analysis_df['Lavenstein Mean'] < 100.0) & (analysis_df['Lavenstein Mean'] >= 0.0)]\n",
    "orig_asr_found_per = (len(orig_asr_found) / len(analysis_df)) * 100\n",
    "print(orig_asr_found_per)\n",
    "print(len(orig_asr_found))\n",
    "orig_asr_found.head()\n",
    "#40.88050314465409\n",
    "#65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_asr_similar = analysis_df[(analysis_df['Flag'] == False) & (analysis_df['Lavenstein Mean'] <= 100.0) & (analysis_df['Lavenstein Mean'] > 0.0)]\n",
    "orig_asr_similar_per = (len(orig_asr_similar) / len(analysis_df)) * 100\n",
    "print(orig_asr_similar_per)\n",
    "orig_asr_similar.head()\n",
    "print(len(orig_asr_similar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_asr_similar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(orig_asr_similar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "orig_asr_nofound = analysis_df[(analysis_df['Flag'] == False) & (analysis_df['Lavenstein Mean'] <= 0.0)]\n",
    "orig_asr_nofound_per = (len(orig_asr_nofound) / len(analysis_df))*100\n",
    "print(orig_asr_nofound_per)\n",
    "orig_asr_nofound.head()\n",
    "print(len(orig_asr_nofound))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[orig_asr_found_complete_per, orig_asr_found_per, orig_asr_similar_per, orig_asr_nofound_per]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[len(orig_asr_found_complete), len(orig_asr_found), len(orig_asr_similar), len(orig_asr_nofound)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python3\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = [orig_asr_found_complete_per, orig_asr_found_per, orig_asr_similar_per, orig_asr_nofound_per]\n",
    "plt.bar(['Correctly Identified', 'Identified with missing entities', 'Similar tag but not identified', 'No Tag identification'], data)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "orig_asr_similar.head(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_simulated_df = combined_df.loc[orig_asr_similar['Sample #'].values.tolist(),['original_sentence','original_tags']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "context_simulated_df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_test = df.groupby(\"Sentence #\")\n",
    "x = pd.DataFrame({\"Sentence\": g_test.apply(lambda sdf: \" \".join(sdf.Word)),\n",
    "                       \"Tag\": g_test.apply(lambda sdf: \",\".join(sdf.Tag))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_no = list(range(0, len(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.index = sentence_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.loc[context_simulated_df.index.tolist(), 'Sentence'] = context_simulated_df['original_sentence'].values.tolist()\n",
    "x.loc[context_simulated_df.index.tolist(), 'Tag'] = context_simulated_df['original_tags'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.head(18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "asr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_simulated_df.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asr_df.loc[context_simulated_df.index.tolist(), 'Sentence'] = context_simulated_df['original_sentence'].values.tolist()\n",
    "asr_df.loc[context_simulated_df.index.tolist(), 'Tag'] = context_simulated_df['original_tags'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asr_df.head(18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = model_test(asr_df['Sentence'].values.tolist(), tokenizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_no = 0\n",
    "dataset=[]\n",
    "for sentences, tags in zip(x['Sentence'].values.tolist(), x['Tag'].values.tolist()):\n",
    "    sentence=sentences.split(\" \")\n",
    "    tag = tags.split(\",\")\n",
    "    for word, label in zip(sentence, tag):\n",
    "        dataset.append((sentence_no, word, label))\n",
    "    sentence_no = sentence_no + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame(dataset, columns=['Sentence #', 'Word', 'Tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = prepare_model_output(test_df, new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics(test_df, ['PER', 'ORG', 'LOC', 'O'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = pd.read_csv('unprocessed_sampled_original.csv')\n",
    "original.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "original = original[:7851]\n",
    "g_original = original.groupby(\"Sentence #\")\n",
    "original_df = pd.DataFrame({'Sentence': g_original.apply(lambda sdf: \" \".join(map(str,sdf.Word))),\n",
    "                      'Tag': g_original.apply(lambda sdf: \",\".join(sdf.Tag))})\n",
    "original_df.reset_index(inplace=True)\n",
    "combined_df = pd.DataFrame({\"original_sentence\": original_df['Sentence'],\n",
    "                           \"original_tags\": original_df['Tag'], \n",
    "                           \"asr_sentence\": asr_df['Sentence'],\n",
    "                           \"asr_tags\": asr_df['Tag']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asr_df, combined_df = prepare_data_for_analysis(test_df, 'unprocessed_sampled_original.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df = pd.DataFrame(pattern_finding(\"PER\", combined_df), columns=['Sample #', 'Original', 'ASR', 'Lavenstein','Lavenstein Mean', 'Flag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(analysis_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_asr_found_complete = analysis_df[(analysis_df['Flag'] == True) & (analysis_df['Lavenstein Mean'] == 100.0)]\n",
    "orig_asr_found_complete_per = (len(orig_asr_found_complete) / len(analysis_df)) * 100\n",
    "print(orig_asr_found_complete_per)\n",
    "orig_asr_found_complete.head()\n",
    "print(len(orig_asr_found_complete))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_asr_found = analysis_df[(analysis_df['Flag'] == True) & (analysis_df['Lavenstein Mean'] < 100.0) & (analysis_df['Lavenstein Mean'] >= 0.0)]\n",
    "orig_asr_found_per = (len(orig_asr_found) / len(analysis_df)) * 100\n",
    "print(orig_asr_found_per)\n",
    "print(len(orig_asr_found))\n",
    "orig_asr_found.head()\n",
    "#40.88050314465409\n",
    "#65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_asr_similar = analysis_df[(analysis_df['Flag'] == False) & (analysis_df['Lavenstein Mean'] <= 100.0) & (analysis_df['Lavenstein Mean'] > 0.0)]\n",
    "orig_asr_similar_per = (len(orig_asr_similar) / len(analysis_df)) * 100\n",
    "print(orig_asr_similar_per)\n",
    "orig_asr_similar.head()\n",
    "print(len(orig_asr_similar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_asr_similar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(orig_asr_similar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "orig_asr_nofound = analysis_df[(analysis_df['Flag'] == False) & (analysis_df['Lavenstein Mean'] <= 0.0)]\n",
    "orig_asr_nofound_per = (len(orig_asr_nofound) / len(analysis_df))*100\n",
    "print(orig_asr_nofound_per)\n",
    "orig_asr_nofound.head()\n",
    "print(len(orig_asr_nofound))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[orig_asr_found_complete_per, orig_asr_found_per, orig_asr_similar_per, orig_asr_nofound_per]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[len(orig_asr_found_complete), len(orig_asr_found), len(orig_asr_similar), len(orig_asr_nofound)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equal_length_words_samples_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finding_context(df, n_grams):\n",
    "    check = []\n",
    "    for sample, original_sentence, asr_sentence, original_tag, asr_tag in zip(\n",
    "                df.index,\n",
    "                df['original_sentence'].values.tolist(),\n",
    "                df['asr_sentence'].values.tolist(),\n",
    "                df['Original'].values.tolist(),\n",
    "                df['ASR'].values.tolist()):\n",
    "\n",
    "        original_label = np.array(original_sentence.split())\n",
    "        asr_label = np.array(asr_sentence.split())\n",
    "        original_tag_ind = [index for index, element in enumerate(original_label) if original_label[index] in original_tag]\n",
    "        asr_tag_ind = [index for index, element in enumerate(asr_label) if asr_label[index] in asr_tag]\n",
    "        original_bigrams = []\n",
    "        asr_bigrams = []\n",
    "        for l in original_tag_ind:\n",
    "            if l <= (len(original_label)-1) - n_grams:\n",
    "                data = \"\"\n",
    "                for c in range(-n_grams, n_grams+1, 1):\n",
    "                    if l+c >= 0:\n",
    "                        data = data + original_label[l + c] + \" \"\n",
    "                    else:\n",
    "                        continue\n",
    "                original_bigrams.append(data)\n",
    "            else:\n",
    "                data = \"\"\n",
    "                for c in range(-n_grams, 1, 1):\n",
    "                    if l+c < len(original_label):\n",
    "                        data = data + original_label[l + c] + \" \"\n",
    "                    else:\n",
    "                        continue\n",
    "                original_bigrams.append(data)\n",
    "        for l in asr_tag_ind:\n",
    "            if l <= (len(asr_label) - 1) - n_grams:\n",
    "                data = \"\"\n",
    "                for c in range(-n_grams, n_grams + 1, 1):\n",
    "                    if l + c >= 0:\n",
    "                        data = data + asr_label[l + c] + \" \"\n",
    "                    else:\n",
    "                        continue\n",
    "                asr_bigrams.append(data)\n",
    "            else:\n",
    "                data = \"\"\n",
    "                for c in range(-n_grams, 1, 1):\n",
    "                    if l + c < len(asr_label):\n",
    "                        data = data + asr_label[l + c] + \" \"\n",
    "                    else:\n",
    "                        continue\n",
    "                asr_bigrams.append(data)\n",
    "        \n",
    "        check.append((sample, original_bigrams[0], original_sentence, original_tag, asr_bigrams[0], asr_sentence, asr_tag))\n",
    "    context = pd.DataFrame(check)\n",
    "    context.columns = ['Sample #', 'Original N-Grams', \"original_sentence\", \"Original\", \"ASR N-Grams\", \"asr_sentence\", \"ASR\"]\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_sampling3(context):\n",
    "    check = []\n",
    "    for sample, original_ngrams, original_sentence, asr_ngrams, asr_sentence, original_tag, asr_tag in zip(\n",
    "            context['Sample #'].values.tolist(),\n",
    "            context['Original N-Grams'].values.tolist(),\n",
    "            context['original_sentence'].values.tolist(),\n",
    "            context['ASR N-Grams'].values.tolist(),\n",
    "            context['asr_sentence'].values.tolist(),\n",
    "            context['Original'].values.tolist(),\n",
    "            context['ASR'].values.tolist()):\n",
    "        \n",
    "        original_ngrams = np.array(original_ngrams.split(\" \"))\n",
    "        asr_ngrams = np.array(asr_ngrams.split(\" \"))\n",
    "        \n",
    "        local_errors = []\n",
    "        i = 0\n",
    "        j = 0\n",
    "        for _original in original_tag:\n",
    "            if _original in asr_tag:\n",
    "                if len(asr_ngrams) < len(asr_tag):\n",
    "                    continue\n",
    "                \n",
    "                print(asr_sentence)\n",
    "                asr_sentence = asr_sentence.replace(\"\".join(asr_ngrams[i].rstrip()), \"\".join(original_ngrams[i].rstrip()))\n",
    "                print(asr_sentence)\n",
    "                #print(check)\n",
    "                i = i + 1\n",
    "                j = j + 1\n",
    "            else:\n",
    "                j = j + 1\n",
    "        check.append((sample, asr_sentence))\n",
    "        print(\"---------------\")\n",
    "    new_asr = pd.DataFrame(check)\n",
    "    return new_asr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = finding_context(equal_length_words_samples_df, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_asr_df = error_sampling3(context)\n",
    "simulated_asr_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asr_df = update_df(asr_df, simulated_asr_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#context = finding_context(variable_length_words_samples_df, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simulated_asr_df = error_sampling3(context)\n",
    "#simulated_asr_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#asr_df = update_df(asr_df, simulated_asr_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [\"and though the famous family of aldus restored its technical excellence , rejecting battered letters ,\",\"most of caxton ' s zone types of an earlier character\", \"are the leaders in this luckless change , though our own baskerville , who was at work some years before them , went much on the same lines\",\n",
    "       \"now come into general use that are obviously a great improvement on the ordinary \\\" modern style \\\" and use in england , which is in fact the bodoni type\" , \"on the top of the jail , continues neild , arawatch - house and a century - box , where two or more guards , with dogs and firearms ,\" ,\n",
    "       \"these courts were extended to centuries later to several large provincial towns , and all were in full activity when neild road ,\" , \"he had been in the employ of a corn - chandler at islington , and went into london with his master ' s cart and horse .\",\n",
    "       \"shameful malpractices of bambridge ,\" , \"if they happened to be in funds - - among whom was the marquis of slego in 1811\", \n",
    "       \"mister . neild , a second howard ,\", \"again the 22 charles ii . c20 order the jailer to keep felons and debtors \\\" separate and apart from one another ,\",\n",
    "       \"prisoners were crowded together in the jail , contrary to the requirements of the for george the 4th .\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"have now come into general use and are obviously a great improvement on the ordinary \\\" modern style \\\" in use in england , which is in fact the bodoni type\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xyz = model_test([test], tokenizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xyz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
