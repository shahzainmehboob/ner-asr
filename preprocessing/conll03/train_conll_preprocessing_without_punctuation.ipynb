{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 10000)\n",
    "pd.set_option('display.max_columns', 10000)\n",
    "pd.set_option('display.width', 10000)\n",
    "pd.set_option('max_colwidth', 10000)\n",
    "import numpy as np\n",
    "import string\n",
    "import transformers\n",
    "from transformers import BertTokenizer, BertConfig\n",
    "from transformers import BertForTokenClassification, AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../data/conll03/train.txt\", sep=\" \")\n",
    "#df = pd.read_csv(\"../../data/conll03/dev.txt\", sep=\" \")\n",
    "#df = pd.read_csv(\"data/test.txt\", sep=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-DOCSTART-</th>\n",
       "      <th>-X-</th>\n",
       "      <th>-X-.1</th>\n",
       "      <th>O</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EU</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-NP</td>\n",
       "      <td>B-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rejects</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>B-VP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>German</td>\n",
       "      <td>JJ</td>\n",
       "      <td>B-NP</td>\n",
       "      <td>B-MISC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>call</td>\n",
       "      <td>NN</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>B-VP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  -DOCSTART-  -X- -X-.1       O\n",
       "0         EU  NNP  B-NP   B-ORG\n",
       "1    rejects  VBZ  B-VP       O\n",
       "2     German   JJ  B-NP  B-MISC\n",
       "3       call   NN  I-NP       O\n",
       "4         to   TO  B-VP       O"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['O'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['-X-', '-X-.1'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['Word', 'Tag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EU</td>\n",
       "      <td>B-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rejects</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>German</td>\n",
       "      <td>B-MISC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>call</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>to</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Word     Tag\n",
       "0       EU   B-ORG\n",
       "1  rejects       O\n",
       "2   German  B-MISC\n",
       "3     call       O\n",
       "4       to       O"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.drop(df[df['Word'] == \"-DOCSTART-\"].index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B-ORG', 'O', 'B-MISC', 'B-PER', 'I-PER', 'B-LOC', 'I-ORG',\n",
       "       'I-MISC', 'I-LOC'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Tag'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = df['Tag'].values\n",
    "words = df['Word'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tags = []\n",
    "for t in tags:\n",
    "    if t == \"B-ORG\":\n",
    "        new_tags.append(\"ORG\")\n",
    "    elif t == \"B-PER\":\n",
    "        new_tags.append(\"PER\")\n",
    "    elif t == \"I-PER\":\n",
    "        new_tags.append(\"PER\")\n",
    "    elif t == \"B-LOC\":\n",
    "        new_tags.append(\"LOC\")\n",
    "    elif t == \"I-ORG\":\n",
    "        new_tags.append(\"ORG\")\n",
    "    elif t == \"I-LOC\":\n",
    "        new_tags.append(\"LOC\")\n",
    "    else:\n",
    "        new_tags.append(\"O\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Tag'], axis=1, inplace=True)\n",
    "df.drop(['Word'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Tag'] = new_tags\n",
    "df['Word'] = words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202388"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_no = 0\n",
    "sentence = []\n",
    "for w in words:\n",
    "    sentence.append(sentence_no)\n",
    "    if w == \".\":\n",
    "        sentence_no = sentence_no + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(0, 'Sentence #', sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ORG</td>\n",
       "      <td>EU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>rejects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>German</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>call</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentence #  Tag     Word\n",
       "0           0  ORG       EU\n",
       "1           0    O  rejects\n",
       "2           0    O   German\n",
       "3           0    O     call\n",
       "4           0    O       to"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_test = df.groupby(\"Sentence #\")\n",
    "x = pd.DataFrame({\"Sentence\": g_test.apply(lambda sdf: \" \".join(map(str,sdf.Word))),\n",
    "                       \"Tag\": g_test.apply(lambda sdf: \",\".join(map(str,sdf.Tag)))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sentence #</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EU rejects German call to boycott British lamb .</td>\n",
       "      <td>ORG,O,O,O,O,O,O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Peter Blackburn BRUSSELS 1996-08-22 The European Commission said on Thursday it disagreed with German advice to consumers to shun British lamb until scientists determine whether mad cow disease can be transmitted to sheep .</td>\n",
       "      <td>PER,PER,LOC,O,O,ORG,ORG,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Germany 's representative to the European Union 's veterinary committee Werner Zwingmann said on Wednesday consumers should buy sheepmeat from countries other than Britain until the scientific advice was clearer .</td>\n",
       "      <td>LOC,O,O,O,O,ORG,ORG,O,O,O,PER,PER,O,O,O,O,O,O,O,O,O,O,O,LOC,O,O,O,O,O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We do n't support any such recommendation because we do n't see any grounds for it , the Commission 's chief spokesman Nikolaus van der Pas told a news briefing .</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,ORG,O,O,O,PER,PER,PER,PER,O,O,O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>He said further scientific study was required and if it was found that action was needed it should be taken by the European Union .</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,ORG,ORG,O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                   Sentence                                                                            Tag\n",
       "Sentence #                                                                                                                                                                                                                                                                                                                \n",
       "0                                                                                                                                                                                          EU rejects German call to boycott British lamb .                                                            ORG,O,O,O,O,O,O,O,O\n",
       "1           Peter Blackburn BRUSSELS 1996-08-22 The European Commission said on Thursday it disagreed with German advice to consumers to shun British lamb until scientists determine whether mad cow disease can be transmitted to sheep .  PER,PER,LOC,O,O,ORG,ORG,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O\n",
       "2                     Germany 's representative to the European Union 's veterinary committee Werner Zwingmann said on Wednesday consumers should buy sheepmeat from countries other than Britain until the scientific advice was clearer .      LOC,O,O,O,O,ORG,ORG,O,O,O,PER,PER,O,O,O,O,O,O,O,O,O,O,O,LOC,O,O,O,O,O,O,O\n",
       "3                                                                        We do n't support any such recommendation because we do n't see any grounds for it , the Commission 's chief spokesman Nikolaus van der Pas told a news briefing .        O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,ORG,O,O,O,PER,PER,PER,PER,O,O,O,O,O\n",
       "4                                                                                                       He said further scientific study was required and if it was found that action was needed it should be taken by the European Union .                          O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,ORG,ORG,O"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def decontracted(phrase):\n",
    "    # general\n",
    "    phrase = re.sub(r\" \\'s\", \"\\'s\", phrase)\n",
    "    phrase = re.sub(r\" \\'t\", \"\\'t\", phrase)\n",
    "    phrase = re.sub(r\" n't\", \"n't\", phrase)\n",
    "    phrase = re.sub(r\" \\'re\", \"\\'re\", phrase)\n",
    "    phrase = re.sub(r\" \\'d\", \"\\'d\", phrase)\n",
    "    phrase = re.sub(r\" \\'ll\", \"\\'ll\", phrase)\n",
    "    phrase = re.sub(r\" \\'t\", \"\\'t\", phrase)\n",
    "    phrase = re.sub(r\" \\'ve\", \"\\'ve\", phrase)\n",
    "    phrase = re.sub(r\" \\'m\", \"\\'m\", phrase)\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 10, 19]\n",
      "31\n",
      "31\n",
      "28\n",
      "['We', 'dont', 'support', 'any', 'such', 'recommendation', 'because', 'we', 'dont', 'see', 'any', 'grounds', 'for', 'it', '', 'the', 'Commissions', 'chief', 'spokesman', 'Nikolaus', 'van', 'der', 'Pas', 'told', 'a', 'news', 'briefing', '']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'ORG', 'O', 'O', 'PER', 'PER', 'PER', 'PER', 'O', 'O', 'O', 'O', 'O']\n",
      "28\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "sentence = \"We do n't support any such recommendation because we do n't see any grounds for it , the Commission 's chief spokesman Nikolaus van der Pas told a news briefing .\"\n",
    "tags = \"O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,ORG,O,O,O,PER,PER,PER,PER,O,O,O,O,O\"\n",
    "words = sentence.split(\" \")\n",
    "ind = [ i for i, word in enumerate(words) if word == \"'s\" or word == \"'t\" or word == \"'re\" or word == \"'d\" or word == \"'ll\" or word == \"'t\" or word == \"'ve\" or word == \"'m\" or word == \"n't\"]\n",
    "print(ind)\n",
    "print(len(words))\n",
    "labels = tags.split(\",\")\n",
    "print(len(labels))\n",
    "sentence = \" \".join(words)\n",
    "#print(sentence)\n",
    "sentence = decontracted(sentence)\n",
    "#print(sentence)\n",
    "tags = [ elem for i, elem in enumerate(labels) if i not in ind]\n",
    "print(len(tags))\n",
    "#words = sentence.split()\n",
    "#tags = [ elem for i, elem in enumerate(labels) if i not in ind]\n",
    "import string\n",
    "stripped = sentence.translate(str.maketrans('', '', string.punctuation))\n",
    "stripped = stripped.split(\" \")\n",
    "#stripped = [w.translate(table) for w in words]\n",
    "#stripped = [x for x in stripped if x]\n",
    "print(stripped)\n",
    "print(tags)\n",
    "print(len(stripped))\n",
    "print(len(tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_data = []\n",
    "sentence_no = 0\n",
    "new_df = []\n",
    "for sentence, tags in zip(x['Sentence'].values.tolist(), x['Tag'].values.tolist()):\n",
    "    words = sentence.split(\" \")\n",
    "    ind = [ i for i, word in enumerate(words) if word == \"'s\" or word == \"'t\" or word == \"'re\" or word == \"'d\" or word == \"'ll\" or word == \"'t\" or word == \"'ve\" or word == \"'m\" or word == \"n't\"]\n",
    "    labels = tags.split(\",\")\n",
    "    sentence = \" \".join(words)\n",
    "    sentence = decontracted(sentence)\n",
    "    tags = [ elem for i, elem in enumerate(labels) if i not in ind]\n",
    "    stripped = sentence.translate(str.maketrans('', '', string.punctuation))\n",
    "    stripped = stripped.split(\" \")\n",
    "    for word, label in zip(stripped, tags):\n",
    "        p_data.append((sentence_no, word, label))\n",
    "    sentence_no = sentence_no + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(p_data, columns=['Sentence #', 'Word', 'Tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>EU</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>rejects</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>German</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>call</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>to</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentence #     Word  Tag\n",
       "0           0       EU  ORG\n",
       "1           0  rejects    O\n",
       "2           0   German    O\n",
       "3           0     call    O\n",
       "4           0       to    O"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df['Word'] == \"\"].index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>EU</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>rejects</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>German</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>call</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>to</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentence #     Word  Tag\n",
       "0           0       EU  ORG\n",
       "1           0  rejects    O\n",
       "2           0   German    O\n",
       "3           0     call    O\n",
       "4           0       to    O"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_test = df.groupby(\"Sentence #\")\n",
    "x = pd.DataFrame({\"Sentence\": g_test.apply(lambda sdf: \" \".join(map(str,sdf.Word))),\n",
    "                       \"Tag\": g_test.apply(lambda sdf: \",\".join(map(str,sdf.Tag)))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sentence #</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EU rejects German call to boycott British lamb</td>\n",
       "      <td>ORG,O,O,O,O,O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Peter Blackburn BRUSSELS 19960822 The European Commission said on Thursday it disagreed with German advice to consumers to shun British lamb until scientists determine whether mad cow disease can be transmitted to sheep</td>\n",
       "      <td>PER,PER,LOC,O,O,ORG,ORG,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Germanys representative to the European Unions veterinary committee Werner Zwingmann said on Wednesday consumers should buy sheepmeat from countries other than Britain until the scientific advice was clearer</td>\n",
       "      <td>LOC,O,O,O,ORG,ORG,O,O,PER,PER,O,O,O,O,O,O,O,O,O,O,O,LOC,O,O,O,O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We dont support any such recommendation because we dont see any grounds for it the Commissions chief spokesman Nikolaus van der Pas told a news briefing</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,ORG,O,O,PER,PER,PER,PER,O,O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>He said further scientific study was required and if it was found that action was needed it should be taken by the European Union</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,ORG,ORG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                               Sentence                                                                          Tag\n",
       "Sentence #                                                                                                                                                                                                                                                                                                          \n",
       "0                                                                                                                                                                                        EU rejects German call to boycott British lamb                                                            ORG,O,O,O,O,O,O,O\n",
       "1           Peter Blackburn BRUSSELS 19960822 The European Commission said on Thursday it disagreed with German advice to consumers to shun British lamb until scientists determine whether mad cow disease can be transmitted to sheep  PER,PER,LOC,O,O,ORG,ORG,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O\n",
       "2                       Germanys representative to the European Unions veterinary committee Werner Zwingmann said on Wednesday consumers should buy sheepmeat from countries other than Britain until the scientific advice was clearer          LOC,O,O,O,ORG,ORG,O,O,PER,PER,O,O,O,O,O,O,O,O,O,O,O,LOC,O,O,O,O,O,O\n",
       "3                                                                              We dont support any such recommendation because we dont see any grounds for it the Commissions chief spokesman Nikolaus van der Pas told a news briefing                O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,ORG,O,O,PER,PER,PER,PER,O,O,O,O\n",
       "4                                                                                                     He said further scientific study was required and if it was found that action was needed it should be taken by the European Union                          O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,ORG,ORG"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased', do_whole_word_mask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceGetter(object):\n",
    "\n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, t) for w, t in zip(s[\"Word\"].values.tolist(),\n",
    "                                                           s[\"Tag\"].values.tolist())]\n",
    "        self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "\n",
    "    def get_next(self):\n",
    "        try:\n",
    "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s\n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "getter = SentenceGetter(df)\n",
    "sentences = [[word[0] for word in sentence] for sentence in getter.sentences]\n",
    "labels = [[s[1] for s in sentence] for sentence in getter.sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_preserve_labels(sentence, text_labels):\n",
    "    tokenized_sentence = []\n",
    "    labels = []\n",
    "\n",
    "    for word, label in zip(sentence, text_labels):\n",
    "\n",
    "        # Tokenize the word and count # of subwords the word is broken into\n",
    "        tokenized_word = tokenizer.tokenize(str(word))\n",
    "        n_subwords = len(tokenized_word)\n",
    "\n",
    "        # Add the tokenized word to the final tokenized word list\n",
    "        tokenized_sentence.extend(tokenized_word)\n",
    "\n",
    "        # Add the same label to the new list of labels `n_subwords` times\n",
    "        labels.extend([label] * n_subwords)\n",
    "\n",
    "    return tokenized_sentence, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_texts_and_labels = [tokenize_and_preserve_labels(sent, labs) for sent, labs in zip(sentences, labels)]\n",
    "#tokenized_texts = [token_label_pair[0] for token_label_pair in tokenized_texts_and_labels]\n",
    "#labels = [token_label_pair[1] for token_label_pair in tokenized_texts_and_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_texts = [token_label_pair[0] for token_label_pair in tokenized_texts_and_labels]\n",
    "labels = [token_label_pair[1] for token_label_pair in tokenized_texts_and_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'la', '##mb'],\n",
       " ['Peter',\n",
       "  'Blackburn',\n",
       "  'BR',\n",
       "  '##US',\n",
       "  '##SE',\n",
       "  '##LS',\n",
       "  '1996',\n",
       "  '##0',\n",
       "  '##8',\n",
       "  '##22',\n",
       "  'The',\n",
       "  'European',\n",
       "  'Commission',\n",
       "  'said',\n",
       "  'on',\n",
       "  'Thursday',\n",
       "  'it',\n",
       "  'disagreed',\n",
       "  'with',\n",
       "  'German',\n",
       "  'advice',\n",
       "  'to',\n",
       "  'consumers',\n",
       "  'to',\n",
       "  's',\n",
       "  '##hun',\n",
       "  'British',\n",
       "  'la',\n",
       "  '##mb',\n",
       "  'until',\n",
       "  'scientists',\n",
       "  'determine',\n",
       "  'whether',\n",
       "  'mad',\n",
       "  'cow',\n",
       "  'disease',\n",
       "  'can',\n",
       "  'be',\n",
       "  'transmitted',\n",
       "  'to',\n",
       "  'sheep'],\n",
       " ['Germany',\n",
       "  '##s',\n",
       "  'representative',\n",
       "  'to',\n",
       "  'the',\n",
       "  'European',\n",
       "  'Union',\n",
       "  '##s',\n",
       "  'veterinary',\n",
       "  'committee',\n",
       "  'Werner',\n",
       "  'Z',\n",
       "  '##wing',\n",
       "  '##mann',\n",
       "  'said',\n",
       "  'on',\n",
       "  'Wednesday',\n",
       "  'consumers',\n",
       "  'should',\n",
       "  'buy',\n",
       "  'sheep',\n",
       "  '##me',\n",
       "  '##at',\n",
       "  'from',\n",
       "  'countries',\n",
       "  'other',\n",
       "  'than',\n",
       "  'Britain',\n",
       "  'until',\n",
       "  'the',\n",
       "  'scientific',\n",
       "  'advice',\n",
       "  'was',\n",
       "  'clearer'],\n",
       " ['We',\n",
       "  'don',\n",
       "  '##t',\n",
       "  'support',\n",
       "  'any',\n",
       "  'such',\n",
       "  'recommendation',\n",
       "  'because',\n",
       "  'we',\n",
       "  'don',\n",
       "  '##t',\n",
       "  'see',\n",
       "  'any',\n",
       "  'grounds',\n",
       "  'for',\n",
       "  'it',\n",
       "  'the',\n",
       "  'Commission',\n",
       "  '##s',\n",
       "  'chief',\n",
       "  'spokesman',\n",
       "  'Nikola',\n",
       "  '##us',\n",
       "  'van',\n",
       "  'der',\n",
       "  'Pa',\n",
       "  '##s',\n",
       "  'told',\n",
       "  'a',\n",
       "  'news',\n",
       "  'brief',\n",
       "  '##ing'],\n",
       " ['He',\n",
       "  'said',\n",
       "  'further',\n",
       "  'scientific',\n",
       "  'study',\n",
       "  'was',\n",
       "  'required',\n",
       "  'and',\n",
       "  'if',\n",
       "  'it',\n",
       "  'was',\n",
       "  'found',\n",
       "  'that',\n",
       "  'action',\n",
       "  'was',\n",
       "  'needed',\n",
       "  'it',\n",
       "  'should',\n",
       "  'be',\n",
       "  'taken',\n",
       "  'by',\n",
       "  'the',\n",
       "  'European',\n",
       "  'Union'],\n",
       " ['He',\n",
       "  'said',\n",
       "  'a',\n",
       "  'proposal',\n",
       "  'last',\n",
       "  'month',\n",
       "  'by',\n",
       "  'EU',\n",
       "  'Farm',\n",
       "  'Commissioner',\n",
       "  'Franz',\n",
       "  'Fi',\n",
       "  '##sch',\n",
       "  '##ler',\n",
       "  'to',\n",
       "  'ban',\n",
       "  'sheep',\n",
       "  'brains',\n",
       "  's',\n",
       "  '##ple',\n",
       "  '##ens',\n",
       "  'and',\n",
       "  'spinal',\n",
       "  'cord',\n",
       "  '##s',\n",
       "  'from',\n",
       "  'the',\n",
       "  'human',\n",
       "  'and',\n",
       "  'animal',\n",
       "  'food',\n",
       "  'chains',\n",
       "  'was',\n",
       "  'a',\n",
       "  'highly',\n",
       "  'specific',\n",
       "  'and',\n",
       "  'pre',\n",
       "  '##ca',\n",
       "  '##ution',\n",
       "  '##ary',\n",
       "  'move',\n",
       "  'to',\n",
       "  'protect',\n",
       "  'human',\n",
       "  'health'],\n",
       " ['Fi',\n",
       "  '##sch',\n",
       "  '##ler',\n",
       "  'proposed',\n",
       "  'EU',\n",
       "  '##wide',\n",
       "  'measures',\n",
       "  'after',\n",
       "  'reports',\n",
       "  'from',\n",
       "  'Britain',\n",
       "  'and',\n",
       "  'France',\n",
       "  'that',\n",
       "  'under',\n",
       "  'laboratory',\n",
       "  'conditions',\n",
       "  'sheep',\n",
       "  'could',\n",
       "  'contract',\n",
       "  'Bo',\n",
       "  '##vin',\n",
       "  '##e',\n",
       "  'S',\n",
       "  '##po',\n",
       "  '##ng',\n",
       "  '##iform',\n",
       "  'En',\n",
       "  '##ce',\n",
       "  '##pha',\n",
       "  '##lop',\n",
       "  '##athy',\n",
       "  'BS',\n",
       "  '##E',\n",
       "  'mad',\n",
       "  'cow',\n",
       "  'disease'],\n",
       " ['But',\n",
       "  'Fi',\n",
       "  '##sch',\n",
       "  '##ler',\n",
       "  'agreed',\n",
       "  'to',\n",
       "  'review',\n",
       "  'his',\n",
       "  'proposal',\n",
       "  'after',\n",
       "  'the',\n",
       "  'EU',\n",
       "  '##s',\n",
       "  'standing',\n",
       "  'veterinary',\n",
       "  'committee',\n",
       "  'mat',\n",
       "  '##ional',\n",
       "  'animal',\n",
       "  'health',\n",
       "  'officials',\n",
       "  'questioned',\n",
       "  'if',\n",
       "  'such',\n",
       "  'action',\n",
       "  'was',\n",
       "  'justified',\n",
       "  'as',\n",
       "  'there',\n",
       "  'was',\n",
       "  'only',\n",
       "  'a',\n",
       "  'slight',\n",
       "  'risk',\n",
       "  'to',\n",
       "  'human',\n",
       "  'health'],\n",
       " ['Spanish',\n",
       "  'Farm',\n",
       "  'Minister',\n",
       "  'Loyola',\n",
       "  'de',\n",
       "  'Pa',\n",
       "  '##la',\n",
       "  '##cio',\n",
       "  'had',\n",
       "  'earlier',\n",
       "  'accused',\n",
       "  'Fi',\n",
       "  '##sch',\n",
       "  '##ler',\n",
       "  'at',\n",
       "  'an',\n",
       "  'EU',\n",
       "  'farm',\n",
       "  'ministers',\n",
       "  'meeting',\n",
       "  'of',\n",
       "  'causing',\n",
       "  'un',\n",
       "  '##ju',\n",
       "  '##st',\n",
       "  '##ified',\n",
       "  'alarm',\n",
       "  'through',\n",
       "  'dangerous',\n",
       "  'general',\n",
       "  '##isation'],\n",
       " ['Only',\n",
       "  'France',\n",
       "  'and',\n",
       "  'Britain',\n",
       "  'backed',\n",
       "  'Fi',\n",
       "  '##sch',\n",
       "  '##lers',\n",
       "  'proposal'],\n",
       " ['The',\n",
       "  'EU',\n",
       "  '##s',\n",
       "  'scientific',\n",
       "  'veterinary',\n",
       "  'and',\n",
       "  'multi',\n",
       "  '##disciplinary',\n",
       "  'committees',\n",
       "  'are',\n",
       "  'due',\n",
       "  'to',\n",
       "  're',\n",
       "  '##ex',\n",
       "  '##amine',\n",
       "  'the',\n",
       "  'issue',\n",
       "  'early',\n",
       "  'next',\n",
       "  'month',\n",
       "  'and',\n",
       "  'make',\n",
       "  'recommendations',\n",
       "  'to',\n",
       "  'the',\n",
       "  'senior',\n",
       "  'veterinary',\n",
       "  'officials'],\n",
       " ['She',\n",
       "  '##ep',\n",
       "  'have',\n",
       "  'long',\n",
       "  'been',\n",
       "  'known',\n",
       "  'to',\n",
       "  'contract',\n",
       "  'scrap',\n",
       "  '##ie',\n",
       "  'a',\n",
       "  'brain',\n",
       "  '##was',\n",
       "  '##ting',\n",
       "  'disease',\n",
       "  'similar',\n",
       "  'to',\n",
       "  'BS',\n",
       "  '##E',\n",
       "  'which',\n",
       "  'is',\n",
       "  'believed',\n",
       "  'to',\n",
       "  'have',\n",
       "  'been',\n",
       "  'transferred',\n",
       "  'to',\n",
       "  'cattle',\n",
       "  'through',\n",
       "  'feed',\n",
       "  'containing',\n",
       "  'animal',\n",
       "  'waste'],\n",
       " ['British',\n",
       "  'farmers',\n",
       "  'denied',\n",
       "  'on',\n",
       "  'Thursday',\n",
       "  'there',\n",
       "  'was',\n",
       "  'any',\n",
       "  'danger',\n",
       "  'to',\n",
       "  'human',\n",
       "  'health',\n",
       "  'from',\n",
       "  'their',\n",
       "  'sheep',\n",
       "  'but',\n",
       "  'expressed',\n",
       "  'concern',\n",
       "  'that',\n",
       "  'German',\n",
       "  'government',\n",
       "  'advice',\n",
       "  'to',\n",
       "  'consumers',\n",
       "  'to',\n",
       "  'avoid',\n",
       "  'British',\n",
       "  'la',\n",
       "  '##mb',\n",
       "  'might',\n",
       "  'influence',\n",
       "  'consumers',\n",
       "  'across',\n",
       "  'Europe'],\n",
       " ['What',\n",
       "  'we',\n",
       "  'have',\n",
       "  'to',\n",
       "  'be',\n",
       "  'extremely',\n",
       "  'careful',\n",
       "  'of',\n",
       "  'is',\n",
       "  'how',\n",
       "  'other',\n",
       "  'countries',\n",
       "  'are',\n",
       "  'going',\n",
       "  'to',\n",
       "  'take',\n",
       "  'Germany',\n",
       "  '##s',\n",
       "  'lead',\n",
       "  'Welsh',\n",
       "  'National',\n",
       "  'Farmers',\n",
       "  'Union',\n",
       "  'N',\n",
       "  '##F',\n",
       "  '##U',\n",
       "  'chairman',\n",
       "  'John',\n",
       "  'Lloyd',\n",
       "  'Jones',\n",
       "  'said',\n",
       "  'on',\n",
       "  'BBC',\n",
       "  'radio'],\n",
       " ['Bonn',\n",
       "  'has',\n",
       "  'led',\n",
       "  'efforts',\n",
       "  'to',\n",
       "  'protect',\n",
       "  'public',\n",
       "  'health',\n",
       "  'after',\n",
       "  'consumer',\n",
       "  'confidence',\n",
       "  'collapsed',\n",
       "  'in',\n",
       "  'March',\n",
       "  'after',\n",
       "  'a',\n",
       "  'British',\n",
       "  'report',\n",
       "  'suggested',\n",
       "  'humans',\n",
       "  'could',\n",
       "  'contract',\n",
       "  'an',\n",
       "  'illness',\n",
       "  'similar',\n",
       "  'to',\n",
       "  'mad',\n",
       "  'cow',\n",
       "  'disease',\n",
       "  'by',\n",
       "  'eating',\n",
       "  'contaminated',\n",
       "  'beef'],\n",
       " ['Germany',\n",
       "  'imported',\n",
       "  '47',\n",
       "  '##60',\n",
       "  '##0',\n",
       "  'sheep',\n",
       "  'from',\n",
       "  'Britain',\n",
       "  'last',\n",
       "  'year',\n",
       "  'nearly',\n",
       "  'half',\n",
       "  'of',\n",
       "  'total',\n",
       "  'imports'],\n",
       " ['It',\n",
       "  'brought',\n",
       "  'in',\n",
       "  '42',\n",
       "  '##75',\n",
       "  'tonnes',\n",
       "  'of',\n",
       "  'British',\n",
       "  'm',\n",
       "  '##utt',\n",
       "  '##on',\n",
       "  'some',\n",
       "  '10',\n",
       "  'percent',\n",
       "  'of',\n",
       "  'overall',\n",
       "  'imports'],\n",
       " ['D',\n",
       "  '##OC',\n",
       "  '##ST',\n",
       "  '##AR',\n",
       "  '##T',\n",
       "  'Rare',\n",
       "  'Hendrix',\n",
       "  'song',\n",
       "  'draft',\n",
       "  'sells',\n",
       "  'for',\n",
       "  'almost',\n",
       "  '1700',\n",
       "  '##0'],\n",
       " ['L',\n",
       "  '##ON',\n",
       "  '##D',\n",
       "  '##ON',\n",
       "  '1996',\n",
       "  '##0',\n",
       "  '##8',\n",
       "  '##22',\n",
       "  'A',\n",
       "  'rare',\n",
       "  'early',\n",
       "  'hand',\n",
       "  '##written',\n",
       "  'draft',\n",
       "  'of',\n",
       "  'a',\n",
       "  'song',\n",
       "  'by',\n",
       "  'US',\n",
       "  'guitar',\n",
       "  'legend',\n",
       "  'Jim',\n",
       "  '##i',\n",
       "  'Hendrix',\n",
       "  'was',\n",
       "  'sold',\n",
       "  'for',\n",
       "  'almost',\n",
       "  '1700',\n",
       "  '##0',\n",
       "  'on',\n",
       "  'Thursday',\n",
       "  'at',\n",
       "  'an',\n",
       "  'auction',\n",
       "  'of',\n",
       "  'some',\n",
       "  'of',\n",
       "  'the',\n",
       "  'late',\n",
       "  'musicians',\n",
       "  'favourite',\n",
       "  'possessions'],\n",
       " ['A',\n",
       "  'Florida',\n",
       "  'restaurant',\n",
       "  'paid',\n",
       "  '109',\n",
       "  '##25',\n",
       "  'pounds',\n",
       "  '169',\n",
       "  '##35',\n",
       "  'for',\n",
       "  'the',\n",
       "  'draft',\n",
       "  'of',\n",
       "  'Ain',\n",
       "  '##t',\n",
       "  'no',\n",
       "  'telling',\n",
       "  'which',\n",
       "  'Hendrix',\n",
       "  'penned',\n",
       "  'on',\n",
       "  'a',\n",
       "  'piece',\n",
       "  'of',\n",
       "  'London',\n",
       "  'hotel',\n",
       "  'station',\n",
       "  '##ery',\n",
       "  'in',\n",
       "  'late',\n",
       "  '1966'],\n",
       " ['At',\n",
       "  'the',\n",
       "  'end',\n",
       "  'of',\n",
       "  'a',\n",
       "  'January',\n",
       "  '1967',\n",
       "  'concert',\n",
       "  'in',\n",
       "  'the',\n",
       "  'English',\n",
       "  'city',\n",
       "  'of',\n",
       "  'Nottingham',\n",
       "  'he',\n",
       "  'threw',\n",
       "  'the',\n",
       "  'sheet',\n",
       "  'of',\n",
       "  'paper',\n",
       "  'into',\n",
       "  'the',\n",
       "  'audience',\n",
       "  'where',\n",
       "  'it',\n",
       "  'was',\n",
       "  'retrieved',\n",
       "  'by',\n",
       "  'a',\n",
       "  'fan'],\n",
       " ['Buy',\n",
       "  '##ers',\n",
       "  'also',\n",
       "  'snapped',\n",
       "  'up',\n",
       "  '16',\n",
       "  'other',\n",
       "  'items',\n",
       "  'that',\n",
       "  'were',\n",
       "  'put',\n",
       "  'up',\n",
       "  'for',\n",
       "  'auction',\n",
       "  'by',\n",
       "  'Hendrix',\n",
       "  '##s',\n",
       "  'former',\n",
       "  'girlfriend',\n",
       "  'Kathy',\n",
       "  'E',\n",
       "  '##tch',\n",
       "  '##ingham',\n",
       "  'who',\n",
       "  'lived',\n",
       "  'with',\n",
       "  'him',\n",
       "  'from',\n",
       "  '1966',\n",
       "  'to',\n",
       "  '1969'],\n",
       " ['They',\n",
       "  'included',\n",
       "  'a',\n",
       "  'black',\n",
       "  'la',\n",
       "  '##c',\n",
       "  '##quer',\n",
       "  'and',\n",
       "  'mother',\n",
       "  'of',\n",
       "  'pearl',\n",
       "  'in',\n",
       "  '##laid',\n",
       "  'box',\n",
       "  'used',\n",
       "  'by',\n",
       "  'Hendrix',\n",
       "  'to',\n",
       "  'store',\n",
       "  'his',\n",
       "  'drugs',\n",
       "  'which',\n",
       "  'an',\n",
       "  'anonymous',\n",
       "  'Australian',\n",
       "  'purchase',\n",
       "  '##r',\n",
       "  'bought',\n",
       "  'for',\n",
       "  '50',\n",
       "  '##60',\n",
       "  'pounds',\n",
       "  '78',\n",
       "  '##45'],\n",
       " ['The',\n",
       "  'guitarist',\n",
       "  'died',\n",
       "  'of',\n",
       "  'a',\n",
       "  'drugs',\n",
       "  'over',\n",
       "  '##dos',\n",
       "  '##e',\n",
       "  'in',\n",
       "  '1970',\n",
       "  'aged',\n",
       "  '27'],\n",
       " ['D',\n",
       "  '##OC',\n",
       "  '##ST',\n",
       "  '##AR',\n",
       "  '##T',\n",
       "  'China',\n",
       "  'says',\n",
       "  'Taiwan',\n",
       "  's',\n",
       "  '##po',\n",
       "  '##ils',\n",
       "  'atmosphere',\n",
       "  'for',\n",
       "  'talks'],\n",
       " ['B',\n",
       "  '##EI',\n",
       "  '##J',\n",
       "  '##ING',\n",
       "  '1996',\n",
       "  '##0',\n",
       "  '##8',\n",
       "  '##22',\n",
       "  'China',\n",
       "  'on',\n",
       "  'Thursday',\n",
       "  'accused',\n",
       "  'Taipei',\n",
       "  'of',\n",
       "  's',\n",
       "  '##po',\n",
       "  '##iling',\n",
       "  'the',\n",
       "  'atmosphere',\n",
       "  'for',\n",
       "  'a',\n",
       "  're',\n",
       "  '##sumption',\n",
       "  'of',\n",
       "  'talks',\n",
       "  'across',\n",
       "  'the',\n",
       "  'Taiwan',\n",
       "  'Strait',\n",
       "  'with',\n",
       "  'a',\n",
       "  'visit',\n",
       "  'to',\n",
       "  'Ukraine',\n",
       "  'by',\n",
       "  'Taiwanese',\n",
       "  'Vice',\n",
       "  'President',\n",
       "  'Lie',\n",
       "  '##n',\n",
       "  'Chan',\n",
       "  'this',\n",
       "  'week',\n",
       "  'that',\n",
       "  'in',\n",
       "  '##fu',\n",
       "  '##riated',\n",
       "  'Beijing'],\n",
       " ['Speaking',\n",
       "  'only',\n",
       "  'hours',\n",
       "  'after',\n",
       "  'Chinese',\n",
       "  'state',\n",
       "  'media',\n",
       "  'said',\n",
       "  'the',\n",
       "  'time',\n",
       "  'was',\n",
       "  'right',\n",
       "  'to',\n",
       "  'engage',\n",
       "  'in',\n",
       "  'political',\n",
       "  'talks',\n",
       "  'with',\n",
       "  'Taiwan',\n",
       "  'Foreign',\n",
       "  'Ministry',\n",
       "  'spokesman',\n",
       "  'Shen',\n",
       "  'Guo',\n",
       "  '##fan',\n",
       "  '##g',\n",
       "  'told',\n",
       "  'Re',\n",
       "  '##uters',\n",
       "  'The',\n",
       "  'necessary',\n",
       "  'atmosphere',\n",
       "  'for',\n",
       "  'the',\n",
       "  'opening',\n",
       "  'of',\n",
       "  'the',\n",
       "  'talks',\n",
       "  'has',\n",
       "  'been',\n",
       "  'disrupted',\n",
       "  'by',\n",
       "  'the',\n",
       "  'Taiwan',\n",
       "  'authorities'],\n",
       " ['State',\n",
       "  'media',\n",
       "  'quoted',\n",
       "  'China',\n",
       "  '##s',\n",
       "  'top',\n",
       "  'ne',\n",
       "  '##got',\n",
       "  '##iator',\n",
       "  'with',\n",
       "  'Taipei',\n",
       "  'Tang',\n",
       "  'Shu',\n",
       "  '##bei',\n",
       "  'as',\n",
       "  'telling',\n",
       "  'a',\n",
       "  'visiting',\n",
       "  'group',\n",
       "  'from',\n",
       "  'Taiwan',\n",
       "  'on',\n",
       "  'Wednesday',\n",
       "  'that',\n",
       "  'it',\n",
       "  'was',\n",
       "  'time',\n",
       "  'for',\n",
       "  'the',\n",
       "  'rivals',\n",
       "  'to',\n",
       "  'hold',\n",
       "  'political',\n",
       "  'talks'],\n",
       " ['Now',\n",
       "  'is',\n",
       "  'the',\n",
       "  'time',\n",
       "  'for',\n",
       "  'the',\n",
       "  'two',\n",
       "  'sides',\n",
       "  'to',\n",
       "  'engage',\n",
       "  'in',\n",
       "  'political',\n",
       "  'talks',\n",
       "  'that',\n",
       "  'is',\n",
       "  'to',\n",
       "  'end',\n",
       "  'the',\n",
       "  'state',\n",
       "  'of',\n",
       "  'hostility',\n",
       "  'Thursday',\n",
       "  '##s',\n",
       "  'overseas',\n",
       "  'edition',\n",
       "  'of',\n",
       "  'the',\n",
       "  'Peoples',\n",
       "  'Daily',\n",
       "  'quoted',\n",
       "  'Tang',\n",
       "  'as',\n",
       "  'saying'],\n",
       " ['The',\n",
       "  'foreign',\n",
       "  'ministry',\n",
       "  '##s',\n",
       "  'Shen',\n",
       "  'told',\n",
       "  'Re',\n",
       "  '##uters',\n",
       "  'Television',\n",
       "  'in',\n",
       "  'an',\n",
       "  'interview',\n",
       "  'he',\n",
       "  'had',\n",
       "  'read',\n",
       "  'reports',\n",
       "  'of',\n",
       "  'Tang',\n",
       "  '##s',\n",
       "  'comments',\n",
       "  'but',\n",
       "  'gave',\n",
       "  'no',\n",
       "  'details',\n",
       "  'of',\n",
       "  'why',\n",
       "  'the',\n",
       "  'ne',\n",
       "  '##got',\n",
       "  '##iator',\n",
       "  'had',\n",
       "  'considered',\n",
       "  'the',\n",
       "  'time',\n",
       "  'right',\n",
       "  'for',\n",
       "  'talks',\n",
       "  'with',\n",
       "  'Taiwan',\n",
       "  'which',\n",
       "  'Beijing',\n",
       "  'considers',\n",
       "  'a',\n",
       "  're',\n",
       "  '##ne',\n",
       "  '##gade',\n",
       "  'province'],\n",
       " ['China',\n",
       "  'which',\n",
       "  'has',\n",
       "  'long',\n",
       "  'opposed',\n",
       "  'all',\n",
       "  'Taipei',\n",
       "  'efforts',\n",
       "  'to',\n",
       "  'gain',\n",
       "  'greater',\n",
       "  'international',\n",
       "  'recognition',\n",
       "  'was',\n",
       "  'in',\n",
       "  '##fu',\n",
       "  '##riated',\n",
       "  'by',\n",
       "  'a',\n",
       "  'visit',\n",
       "  'to',\n",
       "  'Ukraine',\n",
       "  'this',\n",
       "  'week',\n",
       "  'by',\n",
       "  'Taiwanese',\n",
       "  'Vice',\n",
       "  'President',\n",
       "  'Lie',\n",
       "  '##n'],\n",
       " ['D',\n",
       "  '##OC',\n",
       "  '##ST',\n",
       "  '##AR',\n",
       "  '##T',\n",
       "  'China',\n",
       "  'says',\n",
       "  'time',\n",
       "  'right',\n",
       "  'for',\n",
       "  'Taiwan',\n",
       "  'talks'],\n",
       " ['B',\n",
       "  '##EI',\n",
       "  '##J',\n",
       "  '##ING',\n",
       "  '1996',\n",
       "  '##0',\n",
       "  '##8',\n",
       "  '##22',\n",
       "  'China',\n",
       "  'has',\n",
       "  'said',\n",
       "  'it',\n",
       "  'was',\n",
       "  'time',\n",
       "  'for',\n",
       "  'political',\n",
       "  'talks',\n",
       "  'with',\n",
       "  'Taiwan',\n",
       "  'and',\n",
       "  'that',\n",
       "  'the',\n",
       "  'rival',\n",
       "  'island',\n",
       "  'should',\n",
       "  'take',\n",
       "  'practical',\n",
       "  'steps',\n",
       "  'towards',\n",
       "  'that',\n",
       "  'goal'],\n",
       " ['Consul',\n",
       "  '##tations',\n",
       "  'should',\n",
       "  'be',\n",
       "  'held',\n",
       "  'to',\n",
       "  'set',\n",
       "  'the',\n",
       "  'time',\n",
       "  'and',\n",
       "  'format',\n",
       "  'of',\n",
       "  'the',\n",
       "  'talks',\n",
       "  'the',\n",
       "  'official',\n",
       "  'Xi',\n",
       "  '##nh',\n",
       "  '##ua',\n",
       "  'news',\n",
       "  'agency',\n",
       "  'quoted',\n",
       "  'Tang',\n",
       "  'Shu',\n",
       "  '##bei',\n",
       "  'executive',\n",
       "  'vice',\n",
       "  'chairman',\n",
       "  'of',\n",
       "  'the',\n",
       "  'Association',\n",
       "  'for',\n",
       "  'Relations',\n",
       "  'Across',\n",
       "  'the',\n",
       "  'Taiwan',\n",
       "  'Straits',\n",
       "  'as',\n",
       "  'saying',\n",
       "  'late',\n",
       "  'on',\n",
       "  'Wednesday'],\n",
       " ['D',\n",
       "  '##OC',\n",
       "  '##ST',\n",
       "  '##AR',\n",
       "  '##T',\n",
       "  'German',\n",
       "  'July',\n",
       "  'car',\n",
       "  'registration',\n",
       "  '##s',\n",
       "  'up',\n",
       "  '142',\n",
       "  'p',\n",
       "  '##ct',\n",
       "  'y',\n",
       "  '##r',\n",
       "  'y',\n",
       "  '##r'],\n",
       " ['F',\n",
       "  '##RA',\n",
       "  '##N',\n",
       "  '##K',\n",
       "  '##F',\n",
       "  '##UR',\n",
       "  '##T',\n",
       "  '1996',\n",
       "  '##0',\n",
       "  '##8',\n",
       "  '##22',\n",
       "  'German',\n",
       "  'first',\n",
       "  '##time',\n",
       "  'registration',\n",
       "  '##s',\n",
       "  'of',\n",
       "  'motor',\n",
       "  'vehicles',\n",
       "  'jumped',\n",
       "  '142',\n",
       "  'percent',\n",
       "  'in',\n",
       "  'July',\n",
       "  'this',\n",
       "  'year',\n",
       "  'from',\n",
       "  'the',\n",
       "  'year',\n",
       "  '##ear',\n",
       "  '##lier',\n",
       "  'period',\n",
       "  'the',\n",
       "  'Federal',\n",
       "  'office',\n",
       "  'for',\n",
       "  'motor',\n",
       "  'vehicles',\n",
       "  'said',\n",
       "  'on',\n",
       "  'Thursday'],\n",
       " ['The',\n",
       "  'office',\n",
       "  'said',\n",
       "  '35',\n",
       "  '##6',\n",
       "  '##7',\n",
       "  '##25',\n",
       "  'new',\n",
       "  'cars',\n",
       "  'were',\n",
       "  'registered',\n",
       "  'in',\n",
       "  'July',\n",
       "  '1996',\n",
       "  '304',\n",
       "  '##8',\n",
       "  '##50',\n",
       "  'passenger',\n",
       "  'cars',\n",
       "  'and',\n",
       "  '156',\n",
       "  '##13',\n",
       "  'trucks'],\n",
       " ['The',\n",
       "  'figures',\n",
       "  'represent',\n",
       "  'a',\n",
       "  '136',\n",
       "  'percent',\n",
       "  'increase',\n",
       "  'for',\n",
       "  'passenger',\n",
       "  'cars',\n",
       "  'and',\n",
       "  'a',\n",
       "  '22',\n",
       "  'percent',\n",
       "  'decline',\n",
       "  'for',\n",
       "  'trucks',\n",
       "  'from',\n",
       "  'July',\n",
       "  '1995'],\n",
       " ['Motor',\n",
       "  '##bi',\n",
       "  '##ke',\n",
       "  'registration',\n",
       "  'rose',\n",
       "  '32',\n",
       "  '##7',\n",
       "  'percent',\n",
       "  'in',\n",
       "  'the',\n",
       "  'period'],\n",
       " ['The',\n",
       "  'growth',\n",
       "  'was',\n",
       "  'partly',\n",
       "  'due',\n",
       "  'to',\n",
       "  'an',\n",
       "  'increased',\n",
       "  'number',\n",
       "  'of',\n",
       "  'Germans',\n",
       "  'buying',\n",
       "  'German',\n",
       "  'cars',\n",
       "  'abroad',\n",
       "  'while',\n",
       "  'manufacturers',\n",
       "  'said',\n",
       "  'that',\n",
       "  'domestic',\n",
       "  'demand',\n",
       "  'was',\n",
       "  'weak',\n",
       "  'the',\n",
       "  'federal',\n",
       "  'office',\n",
       "  'said'],\n",
       " ['Almost',\n",
       "  'all',\n",
       "  'German',\n",
       "  'car',\n",
       "  'manufacturers',\n",
       "  'posted',\n",
       "  'gains',\n",
       "  'in',\n",
       "  'registration',\n",
       "  'numbers',\n",
       "  'in',\n",
       "  'the',\n",
       "  'period'],\n",
       " ['Volkswagen',\n",
       "  'AG',\n",
       "  'won',\n",
       "  '77',\n",
       "  '##7',\n",
       "  '##19',\n",
       "  'registration',\n",
       "  '##s',\n",
       "  'slightly',\n",
       "  'more',\n",
       "  'than',\n",
       "  'a',\n",
       "  'quarter',\n",
       "  'of',\n",
       "  'the',\n",
       "  'total'],\n",
       " ['Op',\n",
       "  '##el',\n",
       "  'AG',\n",
       "  'together',\n",
       "  'with',\n",
       "  'General',\n",
       "  'Motors',\n",
       "  'came',\n",
       "  'in',\n",
       "  'second',\n",
       "  'place',\n",
       "  'with',\n",
       "  '49',\n",
       "  '##26',\n",
       "  '##9',\n",
       "  'registration',\n",
       "  '##s',\n",
       "  '164',\n",
       "  'percent',\n",
       "  'of',\n",
       "  'the',\n",
       "  'overall',\n",
       "  'figure'],\n",
       " ['Third',\n",
       "  'was',\n",
       "  'Ford',\n",
       "  'with',\n",
       "  '35',\n",
       "  '##5',\n",
       "  '##6',\n",
       "  '##3',\n",
       "  'registration',\n",
       "  '##s',\n",
       "  'or',\n",
       "  '117',\n",
       "  'percent'],\n",
       " ['Only',\n",
       "  'Sea',\n",
       "  '##t',\n",
       "  'and',\n",
       "  'Porsche',\n",
       "  'had',\n",
       "  'fewer',\n",
       "  'registration',\n",
       "  '##s',\n",
       "  'in',\n",
       "  'July',\n",
       "  '1996',\n",
       "  'compared',\n",
       "  'to',\n",
       "  'last',\n",
       "  'years',\n",
       "  'July'],\n",
       " ['Sea',\n",
       "  '##t',\n",
       "  'posted',\n",
       "  '34',\n",
       "  '##20',\n",
       "  'registration',\n",
       "  '##s',\n",
       "  'compared',\n",
       "  'with',\n",
       "  '55',\n",
       "  '##22',\n",
       "  'registration',\n",
       "  '##s',\n",
       "  'in',\n",
       "  'July',\n",
       "  'a',\n",
       "  'year',\n",
       "  'earlier'],\n",
       " ['Porsche',\n",
       "  '##s',\n",
       "  'registration',\n",
       "  '##s',\n",
       "  'fell',\n",
       "  'to',\n",
       "  '55',\n",
       "  '##4',\n",
       "  'from',\n",
       "  '64',\n",
       "  '##3'],\n",
       " ['D',\n",
       "  '##OC',\n",
       "  '##ST',\n",
       "  '##AR',\n",
       "  '##T',\n",
       "  'G',\n",
       "  '##RE',\n",
       "  '##E',\n",
       "  '##K',\n",
       "  'S',\n",
       "  '##OC',\n",
       "  '##IA',\n",
       "  '##L',\n",
       "  '##IS',\n",
       "  '##TS',\n",
       "  'G',\n",
       "  '##IVE',\n",
       "  'G',\n",
       "  '##RE',\n",
       "  '##EN',\n",
       "  'L',\n",
       "  '##IG',\n",
       "  '##HT',\n",
       "  'TO',\n",
       "  'PM',\n",
       "  'F',\n",
       "  '##OR',\n",
       "  'E',\n",
       "  '##LE',\n",
       "  '##CT',\n",
       "  '##ION',\n",
       "  '##S'],\n",
       " ['AT',\n",
       "  '##H',\n",
       "  '##EN',\n",
       "  '##S',\n",
       "  '1996',\n",
       "  '##0',\n",
       "  '##8',\n",
       "  '##22',\n",
       "  'The',\n",
       "  'Greek',\n",
       "  'socialist',\n",
       "  'party',\n",
       "  '##s',\n",
       "  'executive',\n",
       "  'bureau',\n",
       "  'gave',\n",
       "  'the',\n",
       "  'green',\n",
       "  'light',\n",
       "  'to',\n",
       "  'Prime',\n",
       "  'Minister',\n",
       "  'Costa',\n",
       "  '##s',\n",
       "  'Si',\n",
       "  '##mit',\n",
       "  '##is',\n",
       "  'to',\n",
       "  'call',\n",
       "  'snap',\n",
       "  'elections',\n",
       "  'its',\n",
       "  'general',\n",
       "  'secretary',\n",
       "  'Costa',\n",
       "  '##s',\n",
       "  'S',\n",
       "  '##kan',\n",
       "  '##dal',\n",
       "  '##id',\n",
       "  '##is',\n",
       "  'told',\n",
       "  'reporters'],\n",
       " ['Prime',\n",
       "  'Minister',\n",
       "  'Costa',\n",
       "  '##s',\n",
       "  'Si',\n",
       "  '##mit',\n",
       "  '##is',\n",
       "  'is',\n",
       "  'going',\n",
       "  'to',\n",
       "  'make',\n",
       "  'an',\n",
       "  'official',\n",
       "  'announcement',\n",
       "  'after',\n",
       "  'a',\n",
       "  'cabinet',\n",
       "  'meeting',\n",
       "  'later',\n",
       "  'on',\n",
       "  'Thursday',\n",
       "  'said',\n",
       "  'S',\n",
       "  '##kan',\n",
       "  '##dal',\n",
       "  '##id',\n",
       "  '##is']]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_texts[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'la', '##mb']\n"
     ]
    }
   ],
   "source": [
    "for sentence in tokenized_texts:\n",
    "    print(sentence)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "sentence_no = 0\n",
    "new_sentence = []\n",
    "new_data = []\n",
    "for sentence, label in zip(tokenized_texts, labels):\n",
    "    new_tokens = []\n",
    "    new_tags = []\n",
    "    for token, tag in zip(sentence, label):\n",
    "        if token.startswith(\"##\"):\n",
    "            new_tokens[-1] = new_tokens[-1] + token[2:]\n",
    "        else:\n",
    "            new_tokens.append(token)\n",
    "            new_tags.append(tag)\n",
    "    for new_token, new_tag in zip(new_tokens, new_tags):\n",
    "        if new_token in string.punctuation:\n",
    "            continue\n",
    "        else:\n",
    "            new_data.append((sentence_no, new_token, new_tag))\n",
    "    sentence_no = sentence_no + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'EU', 'ORG'),\n",
       " (0, 'rejects', 'O'),\n",
       " (0, 'German', 'O'),\n",
       " (0, 'call', 'O'),\n",
       " (0, 'to', 'O'),\n",
       " (0, 'boycott', 'O'),\n",
       " (0, 'British', 'O'),\n",
       " (0, 'lamb', 'O'),\n",
       " (1, 'Peter', 'PER'),\n",
       " (1, 'Blackburn', 'PER'),\n",
       " (1, 'BRUSSELS', 'LOC'),\n",
       " (1, '19960822', 'O'),\n",
       " (1, 'The', 'O'),\n",
       " (1, 'European', 'ORG'),\n",
       " (1, 'Commission', 'ORG'),\n",
       " (1, 'said', 'O'),\n",
       " (1, 'on', 'O'),\n",
       " (1, 'Thursday', 'O'),\n",
       " (1, 'it', 'O'),\n",
       " (1, 'disagreed', 'O'),\n",
       " (1, 'with', 'O'),\n",
       " (1, 'German', 'O'),\n",
       " (1, 'advice', 'O'),\n",
       " (1, 'to', 'O'),\n",
       " (1, 'consumers', 'O'),\n",
       " (1, 'to', 'O'),\n",
       " (1, 'shun', 'O'),\n",
       " (1, 'British', 'O'),\n",
       " (1, 'lamb', 'O'),\n",
       " (1, 'until', 'O'),\n",
       " (1, 'scientists', 'O'),\n",
       " (1, 'determine', 'O'),\n",
       " (1, 'whether', 'O'),\n",
       " (1, 'mad', 'O'),\n",
       " (1, 'cow', 'O'),\n",
       " (1, 'disease', 'O'),\n",
       " (1, 'can', 'O'),\n",
       " (1, 'be', 'O'),\n",
       " (1, 'transmitted', 'O'),\n",
       " (1, 'to', 'O'),\n",
       " (1, 'sheep', 'O'),\n",
       " (2, 'Germanys', 'LOC'),\n",
       " (2, 'representative', 'O'),\n",
       " (2, 'to', 'O'),\n",
       " (2, 'the', 'O'),\n",
       " (2, 'European', 'ORG'),\n",
       " (2, 'Unions', 'ORG'),\n",
       " (2, 'veterinary', 'O'),\n",
       " (2, 'committee', 'O'),\n",
       " (2, 'Werner', 'PER')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(new_data, columns=['sentence_no', 'Word', 'Tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_no</th>\n",
       "      <th>Word</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>EU</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>rejects</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>German</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>call</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>to</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_no     Word  Tag\n",
       "0            0       EU  ORG\n",
       "1            0  rejects    O\n",
       "2            0   German    O\n",
       "3            0     call    O\n",
       "4            0       to    O"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"../../data/conll03/new_conll_train_preprocessed_without_punctuation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
