# Assessing NER performance on noise ASR output using state-of-the-art BERT
 Machine learning models that process language are rapidly making progress in todayâ€™s world. Among them, recognizing named entities to extract meaningful information from text is an extensively studied problem. When applying NER to speech, it is usually divided into two main steps: (i) An audio sample is passed to an Automated Speech Recognizer (ASR) as input to produce a transcript. (ii) The generated transcript then goes through the NER tagger. However, ASR systems are not perfect, the generated text can be quite noisy with incorrectly recognized words, making downstream applications like NER more difficult. One of the latest NLP milestones is the release of pre-trained language models like BERT. Since BERT is trained on canonical data (i.e. Book Corpus, and Wikipedia), their ability to handle noisy ASR data on downstream tasks like NER is still an open question. Therefore, we investigate the performance of NER on noisy ASR transcripts using state-of-the-art BERT model. We also aim to evaluate the different error patterns from noisy ASR transcripts, their effect on model performance and how it can be improved.
